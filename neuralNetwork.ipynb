{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df88db1e",
   "metadata": {},
   "source": [
    "### CS 421 PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3fa771",
   "metadata": {},
   "source": [
    "In this project, you will be working with data extracted from famous recommender systems type datasets: you are provided with a large set of interactions between users (persons)  and items (movies). Whenever a user \"interacts\" with an item, it watches the movie and gives a mark or \"rating\": you can interpret a rating of \"1\" as a \"like\", a rating of \"-1\" as a \"dislike\" and a rating of \"0\" as a neutral \"meh\" rating. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497cfb8",
   "metadata": {},
   "source": [
    "In this exercise, we will **not** be performing the recommendation task per se. Instead, we will identify *anomalous users*. In the dataset that you are provided with, some of the data was corrupted. Whilst most of the data comes from real life user-item interactions from a famous movie rating website, some \"users\" are anomalous: they were generated by me according to some undisclosed procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa07533",
   "metadata": {},
   "source": [
    "You are provided with two data frames: the first one (\"ratings\") contains the interactions provided to you, and the second one (\"labels\") contains the labels for the users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bde8c2",
   "metadata": {},
   "source": [
    "As you can see, the three columns in \"ratings\" correspond to the user ID, the item ID and the rating. Thus, each row of \"ratings\" contains a single interaction. For instance, if the row \"142, 152, 1\" is present, this means that the user with ID 142 has given the movie 152 a positive rating of \"1\" (\"like\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc20e344",
   "metadata": {},
   "source": [
    "The dataframe \"labels\" has two columns. In the first column we have the user ids, whilst the second column contains the labels. A label of 1 indicates that the user is fake (generated by me), whilst a label of 0 denotes a natural user (coming from real life interactions). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d5102",
   "metadata": {},
   "source": [
    "For instance, if the labels matrix contains the line \"142, 1\", it means that all of the ratings given by the user with id 142 are fake. This means all lines in the dataframe \"ratings\" which start with the userID 142 correspond to fake interactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5399543",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b7fdc",
   "metadata": {},
   "source": [
    "Your task is to be able to classify unseen instances as either anomalies or non anomalies (guess whether they are real users or if they were generated by me). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bedea",
   "metadata": {},
   "source": [
    "There are **far more** normal users than anomalies in the dataset, which makes this a very heavily **unbalanced dataset**. Thus, accuracy will not be a good measure of performance, since simply predicting that every user is normal will give good accuracy. Thus, we need to use some other evaluation metrics (see lecture notes from week 3). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4fe3e",
   "metadata": {},
   "source": [
    "THE **EVALUATION METRICS** are:  THE **AUC** (AREA UNDER CURVE), the **PRECISION**, THE **RECALL**, and the **F1 score**. The **main metric** will be the **AREA UNDER CURVE**, and it will by default be used to rank teams. This means your programs should return an **anomaly score** for each user (the higher the score, the more likely the model think the sample is anomalous).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73885f0",
   "metadata": {},
   "source": [
    "Every few weeks, we will evaluate the performance of each team (on an *unseen test set* I will provide) in terms of AUC, PRECISION, RECALL and F1 score, and rank the teams by **AUC** and by F1 score to distinguish between ties, where a tie is defined by a difference of less than 0.005 in AUC.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed8ac6",
   "metadata": {},
   "source": [
    "The difficulty implied by **the generation procedure of the anomalies MAY CHANGE as the project evolves: depending on how well the teams are doing, I may generate easier or harder anomalies**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79feb2",
   "metadata": {},
   "source": [
    "Together with this file, you are provided with a first batch of labelled examples \"first_batch_with_labels_likes.npz\". You are also provided with the test samples to rank by the next round (without labels) in the file \"second_batch_likes.npz\".\n",
    "\n",
    "The **first round** will take place after recess (week 9): this means that I will **release the next test set on the tuesday of week 9**, and you must hand in your scores for the second batch before the **WEDNESDAY at NOON (11th of October)**. Your submission will be a numpy array containing the **scores** for each of the users I will send you for each test set. We will then look at the results together on the thursday.  \n",
    "\n",
    "We will check everyone's performance in this way every week (once on  week 10, once on week 11 and once on week 12). \n",
    "\n",
    "Whilst performance (expressed in terms of AUC and your ranking compared to other teams) at **each of the check points** (weeks 9 to 12 inclusive) is an **important component** of your **final grade**, the **final report** and the detail of the various methods you will have tried will **also** be very **important**. Ideally, to get perfect marks (A+), you should try at least **two supervised methods** and **two unsupervised methods**, as well as be ranked the **best team** in terms of performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc36c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=np.load(\"first_batch_with_labels_likes.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d834d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[\"X\"]\n",
    "y=data[\"y\"]\n",
    "\n",
    "XX=pd.DataFrame(X)\n",
    "yy=pd.DataFrame(y)\n",
    "XX.rename(columns={0:\"user\",1:\"item\",2:\"rating\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e11141c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1220</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1220</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1220</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1220</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0  1220     6       0\n",
       "1  1220    21       1\n",
       "2  1220    31       0\n",
       "3  1220    33       0\n",
       "4  1220    35      -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6152f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy.rename(columns={0:\"user\",1:\"label\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330351ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  label\n",
       "0     0      1\n",
       "1     1      0\n",
       "2     2      1\n",
       "3     3      0\n",
       "4     4      0\n",
       "5     5      0\n",
       "6     6      0\n",
       "7     7      0\n",
       "8     8      0\n",
       "9     9      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167f3e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [437, 223, 71],\n",
       " 1: [119, 195, 117],\n",
       " 2: [35, 70, 67],\n",
       " 3: [29, 78, 56],\n",
       " 4: [239, 124, 38],\n",
       " 5: [66, 72, 51],\n",
       " 6: [155, 179, 72],\n",
       " 7: [204, 94, 35],\n",
       " 8: [160, 71, 35],\n",
       " 9: [65, 149, 168],\n",
       " 10: [167, 126, 73],\n",
       " 11: [59, 75, 45],\n",
       " 12: [161, 89, 35],\n",
       " 13: [109, 42, 16],\n",
       " 14: [11, 8, 8],\n",
       " 15: [161, 71, 32],\n",
       " 16: [181, 156, 85],\n",
       " 17: [29, 73, 90],\n",
       " 18: [63, 68, 35],\n",
       " 19: [469, 155, 63],\n",
       " 20: [63, 87, 84],\n",
       " 21: [496, 127, 57],\n",
       " 22: [50, 56, 27],\n",
       " 23: [3, 9, 11],\n",
       " 24: [23, 56, 46],\n",
       " 25: [105, 134, 78],\n",
       " 26: [21, 23, 18],\n",
       " 27: [32, 45, 38],\n",
       " 28: [67, 137, 95],\n",
       " 29: [16, 24, 15],\n",
       " 30: [134, 126, 97],\n",
       " 31: [447, 184, 93],\n",
       " 32: [52, 23, 12],\n",
       " 33: [131, 121, 52],\n",
       " 34: [92, 59, 33],\n",
       " 35: [78, 185, 182],\n",
       " 36: [49, 23, 8],\n",
       " 37: [39, 91, 103],\n",
       " 38: [35, 70, 123],\n",
       " 39: [89, 127, 50],\n",
       " 40: [202, 197, 75],\n",
       " 41: [31, 95, 96],\n",
       " 42: [34, 98, 135],\n",
       " 43: [10, 19, 6],\n",
       " 44: [30, 30, 23],\n",
       " 45: [77, 148, 187],\n",
       " 46: [234, 116, 44],\n",
       " 47: [52, 60, 51],\n",
       " 48: [12, 17, 24],\n",
       " 49: [149, 192, 142],\n",
       " 50: [14, 16, 25],\n",
       " 51: [5, 10, 4],\n",
       " 52: [7, 27, 18],\n",
       " 53: [177, 174, 75],\n",
       " 54: [601, 164, 82],\n",
       " 55: [155, 123, 90],\n",
       " 56: [107, 154, 72],\n",
       " 57: [363, 115, 43],\n",
       " 58: [651, 155, 83],\n",
       " 59: [60, 33, 6],\n",
       " 60: [149, 204, 82],\n",
       " 61: [684, 125, 46],\n",
       " 62: [28, 53, 61],\n",
       " 63: [103, 123, 68],\n",
       " 64: [176, 113, 30],\n",
       " 65: [21, 46, 38],\n",
       " 66: [112, 129, 74],\n",
       " 67: [122, 231, 178],\n",
       " 68: [80, 56, 27],\n",
       " 69: [77, 54, 14],\n",
       " 70: [77, 103, 29],\n",
       " 71: [595, 234, 104],\n",
       " 72: [305, 199, 78],\n",
       " 73: [157, 247, 150],\n",
       " 74: [64, 111, 83],\n",
       " 75: [257, 264, 108],\n",
       " 76: [248, 222, 106],\n",
       " 77: [25, 47, 25],\n",
       " 78: [40, 35, 12],\n",
       " 79: [5, 27, 41],\n",
       " 80: [14, 29, 23],\n",
       " 81: [4, 15, 10],\n",
       " 82: [35, 75, 121],\n",
       " 83: [135, 110, 32],\n",
       " 84: [134, 153, 64],\n",
       " 85: [386, 212, 55],\n",
       " 86: [0, 6, 9],\n",
       " 87: [9, 12, 6],\n",
       " 88: [168, 107, 22],\n",
       " 89: [409, 280, 112],\n",
       " 90: [12, 23, 28],\n",
       " 91: [40, 30, 17],\n",
       " 92: [177, 214, 124],\n",
       " 93: [179, 107, 46],\n",
       " 94: [3, 12, 11],\n",
       " 95: [112, 37, 16],\n",
       " 96: [66, 122, 94],\n",
       " 97: [11, 11, 3],\n",
       " 98: [59, 55, 16],\n",
       " 99: [511, 132, 49],\n",
       " 100: [107, 55, 16],\n",
       " 101: [57, 65, 25],\n",
       " 102: [14, 41, 34],\n",
       " 103: [74, 30, 6],\n",
       " 104: [176, 160, 106],\n",
       " 105: [416, 116, 52],\n",
       " 106: [10, 32, 23],\n",
       " 107: [218, 140, 53],\n",
       " 108: [50, 102, 68],\n",
       " 109: [152, 96, 27],\n",
       " 110: [71, 47, 24],\n",
       " 111: [147, 211, 138],\n",
       " 112: [280, 199, 71],\n",
       " 113: [474, 170, 57],\n",
       " 114: [283, 154, 81],\n",
       " 115: [242, 268, 80],\n",
       " 116: [610, 165, 63],\n",
       " 117: [142, 140, 57],\n",
       " 118: [230, 167, 61],\n",
       " 119: [190, 204, 98],\n",
       " 120: [74, 21, 11],\n",
       " 121: [27, 34, 26],\n",
       " 122: [469, 147, 61],\n",
       " 123: [15, 13, 6],\n",
       " 124: [10, 5, 1],\n",
       " 125: [1, 7, 10],\n",
       " 126: [21, 20, 11],\n",
       " 127: [23, 26, 19],\n",
       " 128: [14, 24, 42],\n",
       " 129: [2, 5, 7],\n",
       " 130: [45, 70, 54],\n",
       " 131: [122, 212, 132],\n",
       " 132: [13, 26, 67],\n",
       " 133: [99, 44, 16],\n",
       " 134: [148, 51, 13],\n",
       " 135: [305, 85, 38],\n",
       " 136: [4, 9, 4],\n",
       " 137: [7, 5, 0],\n",
       " 138: [275, 113, 34],\n",
       " 139: [262, 258, 164],\n",
       " 140: [62, 69, 70],\n",
       " 141: [64, 111, 78],\n",
       " 142: [39, 48, 40],\n",
       " 143: [95, 102, 66],\n",
       " 144: [8, 5, 9],\n",
       " 145: [4, 5, 7],\n",
       " 146: [20, 62, 79],\n",
       " 147: [16, 18, 7],\n",
       " 148: [489, 106, 41],\n",
       " 149: [11, 29, 67],\n",
       " 150: [48, 30, 6],\n",
       " 151: [79, 37, 4],\n",
       " 152: [18, 8, 2],\n",
       " 153: [234, 55, 24],\n",
       " 154: [166, 56, 19],\n",
       " 155: [294, 78, 36],\n",
       " 156: [119, 61, 24],\n",
       " 157: [93, 27, 11],\n",
       " 158: [270, 134, 49],\n",
       " 159: [168, 73, 38],\n",
       " 160: [126, 35, 9],\n",
       " 161: [248, 68, 35],\n",
       " 162: [325, 119, 53],\n",
       " 163: [100, 19, 8],\n",
       " 164: [8, 13, 2],\n",
       " 165: [203, 77, 39],\n",
       " 166: [90, 29, 10],\n",
       " 167: [129, 47, 21],\n",
       " 168: [4, 8, 7],\n",
       " 169: [5, 8, 3],\n",
       " 170: [48, 24, 5],\n",
       " 171: [37, 33, 12],\n",
       " 172: [88, 87, 35],\n",
       " 173: [64, 84, 53],\n",
       " 174: [161, 107, 48],\n",
       " 175: [101, 78, 34],\n",
       " 176: [396, 140, 57],\n",
       " 177: [92, 84, 53],\n",
       " 178: [238, 168, 69],\n",
       " 179: [104, 63, 12],\n",
       " 180: [243, 124, 39],\n",
       " 181: [293, 104, 45],\n",
       " 182: [22, 19, 7],\n",
       " 183: [131, 52, 14],\n",
       " 184: [225, 93, 36],\n",
       " 185: [93, 130, 69],\n",
       " 186: [1, 1, 2],\n",
       " 187: [180, 146, 44],\n",
       " 188: [48, 14, 1],\n",
       " 189: [180, 69, 21],\n",
       " 190: [102, 41, 19],\n",
       " 191: [127, 98, 49],\n",
       " 192: [63, 46, 31],\n",
       " 193: [384, 106, 37],\n",
       " 194: [546, 155, 75],\n",
       " 195: [377, 134, 52],\n",
       " 196: [558, 158, 54],\n",
       " 197: [210, 66, 46],\n",
       " 198: [352, 136, 47],\n",
       " 199: [325, 110, 65],\n",
       " 200: [304, 85, 38],\n",
       " 201: [104, 34, 8],\n",
       " 202: [473, 181, 73],\n",
       " 203: [363, 122, 31],\n",
       " 204: [23, 10, 9],\n",
       " 205: [310, 92, 32],\n",
       " 206: [369, 92, 40],\n",
       " 207: [253, 106, 26],\n",
       " 208: [165, 50, 23],\n",
       " 209: [173, 52, 19],\n",
       " 210: [233, 72, 28],\n",
       " 211: [375, 175, 57],\n",
       " 212: [50, 22, 14],\n",
       " 213: [256, 130, 60],\n",
       " 214: [119, 46, 24],\n",
       " 215: [164, 55, 15],\n",
       " 216: [237, 56, 18],\n",
       " 217: [344, 136, 51],\n",
       " 218: [277, 126, 32],\n",
       " 219: [113, 68, 31],\n",
       " 220: [183, 62, 13],\n",
       " 221: [396, 190, 62],\n",
       " 222: [466, 211, 61],\n",
       " 223: [119, 83, 49],\n",
       " 224: [238, 88, 33],\n",
       " 225: [128, 85, 40],\n",
       " 226: [133, 70, 22],\n",
       " 227: [30, 22, 14],\n",
       " 228: [224, 73, 37],\n",
       " 229: [27, 28, 9],\n",
       " 230: [396, 171, 50],\n",
       " 231: [72, 32, 12],\n",
       " 232: [126, 94, 48],\n",
       " 233: [59, 15, 21],\n",
       " 234: [194, 76, 18],\n",
       " 235: [88, 142, 88],\n",
       " 236: [1, 8, 8],\n",
       " 237: [92, 76, 39],\n",
       " 238: [142, 116, 43],\n",
       " 239: [165, 54, 34],\n",
       " 240: [14, 42, 55],\n",
       " 241: [135, 160, 63],\n",
       " 242: [29, 65, 59],\n",
       " 243: [148, 100, 42],\n",
       " 244: [112, 98, 45],\n",
       " 245: [103, 152, 91],\n",
       " 246: [16, 48, 62],\n",
       " 247: [77, 174, 138],\n",
       " 248: [170, 166, 64],\n",
       " 249: [213, 96, 44],\n",
       " 250: [37, 72, 58],\n",
       " 251: [124, 152, 81],\n",
       " 252: [20, 36, 25],\n",
       " 253: [48, 54, 30],\n",
       " 254: [121, 171, 102],\n",
       " 255: [54, 70, 47],\n",
       " 256: [2, 2, 0],\n",
       " 257: [3, 2, 5],\n",
       " 258: [316, 183, 87],\n",
       " 259: [108, 133, 95],\n",
       " 260: [0, 2, 6],\n",
       " 261: [150, 170, 85],\n",
       " 262: [316, 255, 87],\n",
       " 263: [198, 163, 61],\n",
       " 264: [40, 65, 37],\n",
       " 265: [21, 53, 61],\n",
       " 266: [6, 27, 13],\n",
       " 267: [19, 35, 51],\n",
       " 268: [101, 141, 89],\n",
       " 269: [218, 140, 35],\n",
       " 270: [346, 118, 31],\n",
       " 271: [36, 54, 25],\n",
       " 272: [190, 114, 42],\n",
       " 273: [24, 21, 5],\n",
       " 274: [134, 103, 49],\n",
       " 275: [229, 144, 41],\n",
       " 276: [98, 94, 24],\n",
       " 277: [132, 89, 24],\n",
       " 278: [139, 128, 93],\n",
       " 279: [58, 67, 30],\n",
       " 280: [330, 186, 50],\n",
       " 281: [28, 7, 4],\n",
       " 282: [26, 24, 14],\n",
       " 283: [67, 109, 79],\n",
       " 284: [377, 152, 54],\n",
       " 285: [248, 200, 144],\n",
       " 286: [0, 1, 0],\n",
       " 287: [160, 103, 41],\n",
       " 288: [332, 104, 70],\n",
       " 289: [112, 76, 37],\n",
       " 290: [135, 122, 68],\n",
       " 291: [243, 149, 64],\n",
       " 292: [38, 64, 52],\n",
       " 293: [11, 19, 22],\n",
       " 294: [5, 6, 1],\n",
       " 295: [4, 9, 19],\n",
       " 296: [28, 73, 142],\n",
       " 297: [20, 60, 57],\n",
       " 298: [24, 38, 30],\n",
       " 299: [68, 107, 47],\n",
       " 300: [27, 46, 45],\n",
       " 301: [126, 54, 49],\n",
       " 302: [233, 155, 91],\n",
       " 303: [75, 40, 23],\n",
       " 304: [52, 49, 28],\n",
       " 305: [303, 150, 52],\n",
       " 306: [101, 65, 23],\n",
       " 307: [263, 147, 54],\n",
       " 308: [86, 122, 63],\n",
       " 309: [103, 148, 51],\n",
       " 310: [99, 133, 76],\n",
       " 311: [186, 197, 80],\n",
       " 312: [157, 174, 99],\n",
       " 313: [31, 28, 13],\n",
       " 314: [207, 25, 21],\n",
       " 315: [75, 83, 56],\n",
       " 316: [423, 165, 67],\n",
       " 317: [7, 13, 12],\n",
       " 318: [34, 56, 25],\n",
       " 319: [19, 36, 15],\n",
       " 320: [11, 45, 75],\n",
       " 321: [64, 149, 144],\n",
       " 322: [33, 15, 2],\n",
       " 323: [160, 65, 32],\n",
       " 324: [104, 77, 32],\n",
       " 325: [124, 110, 66],\n",
       " 326: [73, 79, 35],\n",
       " 327: [7, 13, 10],\n",
       " 328: [45, 85, 50],\n",
       " 329: [20, 29, 35],\n",
       " 330: [47, 24, 7],\n",
       " 331: [64, 20, 11],\n",
       " 332: [61, 61, 39],\n",
       " 333: [117, 55, 35],\n",
       " 334: [103, 121, 48],\n",
       " 335: [0, 3, 4],\n",
       " 336: [18, 11, 6],\n",
       " 337: [191, 170, 66],\n",
       " 338: [73, 44, 8],\n",
       " 339: [47, 31, 10],\n",
       " 340: [199, 118, 26],\n",
       " 341: [13, 14, 12],\n",
       " 342: [63, 21, 2],\n",
       " 343: [14, 11, 3],\n",
       " 344: [12, 23, 20],\n",
       " 345: [8, 13, 18],\n",
       " 346: [8, 8, 5],\n",
       " 347: [110, 38, 19],\n",
       " 348: [262, 152, 65],\n",
       " 349: [74, 118, 67],\n",
       " 350: [11, 31, 27],\n",
       " 351: [96, 41, 21],\n",
       " 352: [141, 122, 45],\n",
       " 353: [147, 137, 33],\n",
       " 354: [252, 90, 44],\n",
       " 355: [317, 114, 30],\n",
       " 356: [12, 10, 10],\n",
       " 357: [184, 167, 57],\n",
       " 358: [15, 12, 9],\n",
       " 359: [14, 27, 41],\n",
       " 360: [40, 46, 43],\n",
       " 361: [68, 63, 35],\n",
       " 362: [26, 52, 57],\n",
       " 363: [5, 21, 42],\n",
       " 364: [52, 54, 33],\n",
       " 365: [184, 83, 41],\n",
       " 366: [218, 135, 62],\n",
       " 367: [36, 68, 58],\n",
       " 368: [120, 106, 62],\n",
       " 369: [45, 64, 46],\n",
       " 370: [13, 16, 14],\n",
       " 371: [121, 95, 48],\n",
       " 372: [35, 58, 32],\n",
       " 373: [87, 122, 72],\n",
       " 374: [49, 52, 14],\n",
       " 375: [4, 9, 7],\n",
       " 376: [58, 68, 58],\n",
       " 377: [68, 77, 48],\n",
       " 378: [230, 137, 36],\n",
       " 379: [22, 45, 36],\n",
       " 380: [24, 33, 14],\n",
       " 381: [45, 64, 21],\n",
       " 382: [53, 66, 32],\n",
       " 383: [12, 21, 26],\n",
       " 384: [13, 22, 32],\n",
       " 385: [19, 40, 29],\n",
       " 386: [241, 81, 41],\n",
       " 387: [3, 5, 16],\n",
       " 388: [596, 175, 82],\n",
       " 389: [95, 68, 27],\n",
       " 390: [41, 63, 48],\n",
       " 391: [18, 45, 31],\n",
       " 392: [6, 5, 0],\n",
       " 393: [137, 176, 97],\n",
       " 394: [132, 145, 66],\n",
       " 395: [56, 94, 52],\n",
       " 396: [131, 109, 64],\n",
       " 397: [156, 176, 125],\n",
       " 398: [75, 35, 8],\n",
       " 399: [66, 48, 39],\n",
       " 400: [14, 7, 4],\n",
       " 401: [52, 93, 98],\n",
       " 402: [188, 118, 48],\n",
       " 403: [22, 38, 20],\n",
       " 404: [141, 174, 108],\n",
       " 405: [70, 57, 41],\n",
       " 406: [101, 155, 114],\n",
       " 407: [307, 203, 72],\n",
       " 408: [55, 26, 2],\n",
       " 409: [49, 38, 9],\n",
       " 410: [72, 44, 21],\n",
       " 411: [8, 16, 19],\n",
       " 412: [431, 192, 48],\n",
       " 413: [66, 79, 41],\n",
       " 414: [9, 11, 2],\n",
       " 415: [260, 103, 49],\n",
       " 416: [34, 56, 38],\n",
       " 417: [7, 11, 5],\n",
       " 418: [150, 59, 33],\n",
       " 419: [16, 40, 49],\n",
       " 420: [14, 24, 8],\n",
       " 421: [126, 57, 18],\n",
       " 422: [38, 10, 4],\n",
       " 423: [5, 16, 23],\n",
       " 424: [62, 31, 12],\n",
       " 425: [299, 147, 52],\n",
       " 426: [43, 31, 14],\n",
       " 427: [32, 35, 48],\n",
       " 428: [127, 59, 15],\n",
       " 429: [30, 73, 109],\n",
       " 430: [543, 124, 63],\n",
       " 431: [142, 147, 75],\n",
       " 432: [223, 187, 59],\n",
       " 433: [37, 64, 26],\n",
       " 434: [65, 65, 15],\n",
       " 435: [184, 56, 13],\n",
       " 436: [37, 22, 21],\n",
       " 437: [85, 88, 32],\n",
       " 438: [126, 113, 68],\n",
       " 439: [54, 39, 15],\n",
       " 440: [44, 21, 7],\n",
       " 441: [70, 75, 47],\n",
       " 442: [62, 89, 30],\n",
       " 443: [104, 76, 19],\n",
       " 444: [245, 133, 63],\n",
       " 445: [68, 66, 26],\n",
       " 446: [56, 27, 6],\n",
       " 447: [26, 21, 17],\n",
       " 448: [37, 52, 47],\n",
       " 449: [177, 64, 44],\n",
       " 450: [17, 19, 14],\n",
       " 451: [91, 74, 27],\n",
       " 452: [144, 126, 47],\n",
       " 453: [116, 132, 49],\n",
       " 454: [93, 41, 10],\n",
       " 455: [9, 42, 45],\n",
       " 456: [103, 81, 33],\n",
       " 457: [146, 129, 65],\n",
       " 458: [18, 63, 52],\n",
       " 459: [53, 46, 13],\n",
       " 460: [7, 17, 54],\n",
       " 461: [89, 107, 44],\n",
       " 462: [23, 3, 3],\n",
       " 463: [73, 16, 4],\n",
       " 464: [86, 68, 17],\n",
       " 465: [11, 12, 19],\n",
       " 466: [20, 61, 76],\n",
       " 467: [33, 23, 10],\n",
       " 468: [38, 10, 3],\n",
       " 469: [98, 53, 29],\n",
       " 470: [77, 51, 21],\n",
       " 471: [13, 13, 9],\n",
       " 472: [165, 157, 42],\n",
       " 473: [133, 118, 40],\n",
       " 474: [24, 43, 44],\n",
       " 475: [93, 20, 9],\n",
       " 476: [73, 60, 22],\n",
       " 477: [125, 91, 29],\n",
       " 478: [39, 27, 14],\n",
       " 479: [54, 31, 10],\n",
       " 480: [27, 26, 16],\n",
       " 481: [183, 118, 60],\n",
       " 482: [145, 96, 53],\n",
       " 483: [37, 52, 40],\n",
       " 484: [53, 26, 12],\n",
       " 485: [3, 10, 29],\n",
       " 486: [405, 174, 87],\n",
       " 487: [12, 15, 11],\n",
       " 488: [42, 91, 47],\n",
       " 489: [6, 8, 3],\n",
       " 490: [95, 144, 129],\n",
       " 491: [16, 14, 2],\n",
       " 492: [60, 18, 0],\n",
       " 493: [42, 78, 17],\n",
       " 494: [61, 37, 13],\n",
       " 495: [11, 7, 2],\n",
       " 496: [114, 35, 9],\n",
       " 497: [56, 89, 57],\n",
       " 498: [16, 13, 10],\n",
       " 499: [114, 96, 42],\n",
       " 500: [104, 31, 8],\n",
       " 501: [44, 59, 42],\n",
       " 502: [73, 112, 73],\n",
       " 503: [46, 119, 103],\n",
       " 504: [54, 72, 46],\n",
       " 505: [1, 15, 16],\n",
       " 506: [49, 69, 53],\n",
       " 507: [43, 46, 36],\n",
       " 508: [240, 122, 40],\n",
       " 509: [103, 67, 37],\n",
       " 510: [36, 40, 22],\n",
       " 511: [3, 2, 8],\n",
       " 512: [166, 168, 114],\n",
       " 513: [248, 94, 42],\n",
       " 514: [46, 19, 14],\n",
       " 515: [13, 12, 2],\n",
       " 516: [30, 57, 62],\n",
       " 517: [66, 53, 44],\n",
       " 518: [75, 129, 171],\n",
       " 519: [17, 25, 38],\n",
       " 520: [17, 47, 76],\n",
       " 521: [42, 33, 32],\n",
       " 522: [14, 49, 50],\n",
       " 523: [29, 70, 57],\n",
       " 524: [295, 125, 72],\n",
       " 525: [86, 82, 29],\n",
       " 526: [281, 122, 44],\n",
       " 527: [131, 104, 48],\n",
       " 528: [31, 59, 97],\n",
       " 529: [73, 79, 37],\n",
       " 530: [71, 126, 86],\n",
       " 531: [82, 61, 22],\n",
       " 532: [36, 55, 26],\n",
       " 533: [240, 179, 71],\n",
       " 534: [80, 111, 102],\n",
       " 535: [279, 120, 66],\n",
       " 536: [195, 106, 49],\n",
       " 537: [13, 24, 18],\n",
       " 538: [6, 14, 10],\n",
       " 539: [26, 67, 51],\n",
       " 540: [130, 113, 34],\n",
       " 541: [55, 19, 13],\n",
       " 542: [4, 12, 23],\n",
       " 543: [426, 110, 45],\n",
       " 544: [79, 38, 12],\n",
       " 545: [34, 53, 36],\n",
       " 546: [98, 77, 35],\n",
       " 547: [2, 0, 2],\n",
       " 548: [13, 26, 34],\n",
       " 549: [16, 19, 6],\n",
       " 550: [6, 10, 31],\n",
       " 551: [21, 13, 5],\n",
       " 552: [16, 4, 6],\n",
       " 553: [348, 188, 80],\n",
       " 554: [129, 99, 84],\n",
       " 555: [72, 43, 13],\n",
       " 556: [56, 90, 92],\n",
       " 557: [16, 52, 75],\n",
       " 558: [9, 5, 1],\n",
       " 559: [8, 3, 1],\n",
       " 560: [94, 111, 72],\n",
       " 561: [3, 14, 0],\n",
       " 562: [45, 48, 15],\n",
       " 563: [88, 90, 38],\n",
       " 564: [25, 47, 66],\n",
       " 565: [47, 26, 9],\n",
       " 566: [26, 24, 11],\n",
       " 567: [3, 13, 12],\n",
       " 568: [5, 12, 11],\n",
       " 569: [147, 119, 43],\n",
       " 570: [8, 26, 37],\n",
       " 571: [125, 94, 39],\n",
       " 572: [27, 29, 17],\n",
       " 573: [11, 4, 8],\n",
       " 574: [87, 111, 83],\n",
       " 575: [46, 41, 42],\n",
       " 576: [12, 15, 2],\n",
       " 577: [25, 17, 6],\n",
       " 578: [173, 78, 35],\n",
       " 579: [113, 68, 22],\n",
       " 580: [48, 21, 12],\n",
       " 581: [55, 34, 30],\n",
       " 582: [294, 172, 71],\n",
       " 583: [34, 31, 20],\n",
       " 584: [236, 178, 72],\n",
       " 585: [70, 77, 28],\n",
       " 586: [51, 21, 8],\n",
       " 587: [0, 0, 5],\n",
       " 588: [32, 64, 36],\n",
       " 589: [276, 216, 52],\n",
       " 590: [350, 96, 44],\n",
       " 591: [100, 119, 63],\n",
       " 592: [209, 88, 55],\n",
       " 593: [503, 128, 80],\n",
       " 594: [299, 156, 52],\n",
       " 595: [41, 36, 16],\n",
       " 596: [153, 68, 28],\n",
       " 597: [92, 53, 15],\n",
       " 598: [8, 3, 3],\n",
       " 599: [12, 28, 17],\n",
       " 600: [8, 8, 19],\n",
       " 601: [16, 18, 10],\n",
       " 602: [134, 164, 79],\n",
       " 603: [21, 38, 30],\n",
       " 604: [3, 7, 3],\n",
       " 605: [232, 220, 94],\n",
       " 606: [117, 155, 145],\n",
       " 607: [34, 69, 36],\n",
       " 608: [12, 23, 20],\n",
       " 609: [4, 24, 14],\n",
       " 610: [269, 170, 43],\n",
       " 611: [8, 38, 52],\n",
       " 612: [279, 179, 76],\n",
       " 613: [110, 142, 92],\n",
       " 614: [12, 19, 14],\n",
       " 615: [55, 75, 45],\n",
       " 616: [23, 29, 16],\n",
       " 617: [252, 68, 28],\n",
       " 618: [43, 58, 42],\n",
       " 619: [6, 3, 3],\n",
       " 620: [15, 15, 10],\n",
       " 621: [182, 95, 40],\n",
       " 622: [9, 10, 9],\n",
       " 623: [115, 130, 49],\n",
       " 624: [73, 22, 9],\n",
       " 625: [55, 25, 13],\n",
       " 626: [193, 179, 53],\n",
       " 627: [1, 2, 1],\n",
       " 628: [15, 4, 3],\n",
       " 629: [24, 23, 14],\n",
       " 630: [0, 6, 11],\n",
       " 631: [35, 50, 35],\n",
       " 632: [162, 71, 34],\n",
       " 633: [465, 145, 70],\n",
       " 634: [122, 116, 50],\n",
       " 635: [115, 44, 13],\n",
       " 636: [292, 157, 51],\n",
       " 637: [104, 80, 51],\n",
       " 638: [194, 79, 30],\n",
       " 639: [10, 29, 30],\n",
       " 640: [200, 60, 21],\n",
       " 641: [2, 2, 1],\n",
       " 642: [22, 41, 37],\n",
       " 643: [42, 29, 8],\n",
       " 644: [77, 76, 43],\n",
       " 645: [24, 8, 5],\n",
       " 646: [32, 81, 66],\n",
       " 647: [11, 28, 13],\n",
       " 648: [172, 157, 54],\n",
       " 649: [155, 168, 101],\n",
       " 650: [297, 169, 74],\n",
       " 651: [193, 121, 41],\n",
       " 652: [61, 124, 94],\n",
       " 653: [302, 192, 81],\n",
       " 654: [26, 75, 92],\n",
       " 655: [22, 45, 30],\n",
       " 656: [22, 47, 40],\n",
       " 657: [223, 120, 59],\n",
       " 658: [16, 9, 5],\n",
       " 659: [5, 19, 20],\n",
       " 660: [12, 17, 25],\n",
       " 661: [136, 146, 56],\n",
       " 662: [159, 96, 28],\n",
       " 663: [342, 135, 70],\n",
       " 664: [15, 45, 48],\n",
       " 665: [41, 32, 17],\n",
       " 666: [17, 17, 3],\n",
       " 667: [0, 1, 0],\n",
       " 668: [84, 96, 43],\n",
       " 669: [147, 109, 38],\n",
       " 670: [107, 86, 21],\n",
       " 671: [83, 61, 21],\n",
       " 672: [4, 23, 8],\n",
       " 673: [6, 14, 27],\n",
       " 674: [21, 35, 25],\n",
       " 675: [6, 4, 1],\n",
       " 676: [7, 7, 7],\n",
       " 677: [18, 54, 21],\n",
       " 678: [43, 10, 7],\n",
       " 679: [168, 117, 54],\n",
       " 680: [443, 144, 59],\n",
       " 681: [50, 38, 14],\n",
       " 682: [2, 2, 2],\n",
       " 683: [19, 18, 14],\n",
       " 684: [80, 86, 82],\n",
       " 685: [25, 81, 63],\n",
       " 686: [6, 5, 3],\n",
       " 687: [28, 68, 35],\n",
       " 688: [6, 3, 3],\n",
       " 689: [70, 66, 25],\n",
       " 690: [1, 9, 12],\n",
       " 691: [272, 138, 61],\n",
       " 692: [88, 72, 24],\n",
       " 693: [27, 74, 64],\n",
       " 694: [0, 5, 0],\n",
       " 695: [91, 100, 69],\n",
       " 696: [31, 30, 19],\n",
       " 697: [9, 7, 2],\n",
       " 698: [13, 7, 2],\n",
       " 699: [27, 26, 11],\n",
       " 700: [0, 1, 4],\n",
       " 701: [154, 142, 83],\n",
       " 702: [68, 116, 96],\n",
       " 703: [104, 97, 65],\n",
       " 704: [82, 62, 41],\n",
       " 705: [22, 6, 4],\n",
       " 706: [112, 86, 46],\n",
       " 707: [77, 35, 10],\n",
       " 708: [1, 9, 5],\n",
       " 709: [140, 153, 75],\n",
       " 710: [207, 132, 42],\n",
       " 711: [2, 2, 0],\n",
       " 712: [32, 69, 26],\n",
       " 713: [1, 7, 3],\n",
       " 714: [4, 8, 9],\n",
       " 715: [13, 30, 17],\n",
       " 716: [209, 110, 34],\n",
       " 717: [18, 56, 34],\n",
       " 718: [69, 39, 23],\n",
       " 719: [79, 66, 36],\n",
       " 720: [88, 84, 51],\n",
       " 721: [281, 140, 56],\n",
       " 722: [5, 20, 14],\n",
       " 723: [21, 35, 40],\n",
       " 724: [85, 91, 63],\n",
       " 725: [51, 64, 22],\n",
       " 726: [23, 13, 4],\n",
       " 727: [22, 10, 2],\n",
       " 728: [1, 4, 2],\n",
       " 729: [3, 7, 2],\n",
       " 730: [4, 4, 2],\n",
       " 731: [8, 15, 11],\n",
       " 732: [24, 11, 7],\n",
       " 733: [34, 16, 3],\n",
       " 734: [168, 99, 28],\n",
       " 735: [150, 70, 19],\n",
       " 736: [94, 92, 24],\n",
       " 737: [24, 41, 17],\n",
       " 738: [48, 84, 74],\n",
       " 739: [38, 6, 6],\n",
       " 740: [74, 101, 44],\n",
       " 741: [1, 7, 1],\n",
       " 742: [232, 91, 52],\n",
       " 743: [81, 101, 67],\n",
       " 744: [140, 88, 38],\n",
       " 745: [142, 147, 93],\n",
       " 746: [45, 79, 51],\n",
       " 747: [84, 138, 70],\n",
       " 748: [306, 140, 39],\n",
       " 749: [66, 130, 76],\n",
       " 750: [157, 67, 15],\n",
       " 751: [21, 44, 53],\n",
       " 752: [16, 7, 7],\n",
       " 753: [17, 19, 15],\n",
       " 754: [82, 66, 15],\n",
       " 755: [91, 64, 27],\n",
       " 756: [3, 3, 6],\n",
       " 757: [61, 51, 10],\n",
       " 758: [4, 6, 12],\n",
       " 759: [1, 3, 1],\n",
       " 760: [111, 80, 20],\n",
       " 761: [96, 122, 58],\n",
       " 762: [5, 15, 5],\n",
       " 763: [239, 127, 51],\n",
       " 764: [110, 81, 14],\n",
       " 765: [128, 27, 8],\n",
       " 766: [5, 9, 5],\n",
       " 767: [66, 81, 31],\n",
       " 768: [8, 22, 17],\n",
       " 769: [77, 115, 70],\n",
       " 770: [29, 56, 53],\n",
       " 771: [31, 45, 22],\n",
       " 772: [28, 74, 62],\n",
       " 773: [71, 73, 29],\n",
       " 774: [123, 91, 33],\n",
       " 775: [108, 104, 39],\n",
       " 776: [6, 12, 10],\n",
       " 777: [4, 10, 2],\n",
       " 778: [224, 81, 44],\n",
       " 779: [274, 90, 20],\n",
       " 780: [234, 99, 30],\n",
       " 781: [24, 29, 10],\n",
       " 782: [6, 18, 10],\n",
       " 783: [200, 126, 32],\n",
       " 784: [184, 97, 34],\n",
       " 785: [3, 5, 7],\n",
       " 786: [101, 66, 22],\n",
       " 787: [3, 7, 14],\n",
       " 788: [2, 9, 2],\n",
       " 789: [29, 42, 14],\n",
       " 790: [1, 9, 6],\n",
       " 791: [1, 2, 5],\n",
       " 792: [36, 99, 67],\n",
       " 793: [78, 81, 46],\n",
       " 794: [29, 54, 46],\n",
       " 795: [6, 6, 5],\n",
       " 796: [36, 49, 25],\n",
       " 797: [68, 70, 45],\n",
       " 798: [197, 107, 32],\n",
       " 799: [0, 3, 4],\n",
       " 800: [6, 10, 8],\n",
       " 801: [2, 18, 16],\n",
       " 802: [48, 21, 4],\n",
       " 803: [228, 57, 33],\n",
       " 804: [46, 31, 14],\n",
       " 805: [41, 56, 14],\n",
       " 806: [116, 123, 53],\n",
       " 807: [43, 25, 10],\n",
       " 808: [164, 111, 41],\n",
       " 809: [22, 30, 11],\n",
       " 810: [42, 49, 15],\n",
       " 811: [43, 76, 25],\n",
       " 812: [8, 25, 39],\n",
       " 813: [348, 99, 45],\n",
       " 814: [63, 62, 34],\n",
       " 815: [245, 114, 47],\n",
       " 816: [116, 99, 20],\n",
       " 817: [87, 87, 35],\n",
       " 818: [9, 7, 1],\n",
       " 819: [1, 2, 2],\n",
       " 820: [261, 112, 30],\n",
       " 821: [49, 77, 30],\n",
       " 822: [50, 88, 54],\n",
       " 823: [21, 35, 32],\n",
       " 824: [132, 75, 49],\n",
       " 825: [11, 15, 4],\n",
       " 826: [34, 33, 17],\n",
       " 827: [104, 29, 12],\n",
       " 828: [3, 11, 21],\n",
       " 829: [3, 2, 1],\n",
       " 830: [52, 42, 15],\n",
       " 831: [175, 91, 28],\n",
       " 832: [9, 10, 4],\n",
       " 833: [6, 16, 14],\n",
       " 834: [6, 20, 16],\n",
       " 835: [55, 36, 12],\n",
       " 836: [20, 51, 18],\n",
       " 837: [14, 12, 2],\n",
       " 838: [1, 5, 0],\n",
       " 839: [175, 99, 27],\n",
       " 840: [3, 15, 3],\n",
       " 841: [30, 40, 52],\n",
       " 842: [89, 73, 28],\n",
       " 843: [137, 94, 32],\n",
       " 844: [35, 20, 7],\n",
       " 845: [20, 37, 18],\n",
       " 846: [18, 34, 22],\n",
       " 847: [14, 8, 2],\n",
       " 848: [130, 98, 33],\n",
       " 849: [28, 33, 20],\n",
       " 850: [92, 63, 20],\n",
       " 851: [6, 24, 11],\n",
       " 852: [25, 27, 12],\n",
       " 853: [0, 1, 1],\n",
       " 854: [140, 120, 36],\n",
       " 855: [62, 66, 39],\n",
       " 856: [44, 79, 65],\n",
       " 857: [134, 80, 27],\n",
       " 858: [52, 29, 5],\n",
       " 859: [18, 40, 27],\n",
       " 860: [20, 40, 36],\n",
       " 861: [80, 90, 30],\n",
       " 862: [307, 88, 42],\n",
       " 863: [18, 43, 24],\n",
       " 864: [19, 11, 4],\n",
       " 865: [21, 58, 27],\n",
       " 866: [2, 6, 4],\n",
       " 867: [137, 81, 34],\n",
       " 868: [49, 51, 18],\n",
       " 869: [141, 79, 34],\n",
       " 870: [148, 72, 17],\n",
       " 871: [57, 44, 12],\n",
       " 872: [102, 61, 14],\n",
       " 873: [43, 56, 35],\n",
       " 874: [35, 40, 5],\n",
       " 875: [1, 0, 0],\n",
       " 876: [18, 9, 3],\n",
       " 877: [28, 17, 5],\n",
       " 878: [40, 67, 36],\n",
       " 879: [95, 44, 14],\n",
       " 880: [21, 55, 43],\n",
       " 881: [105, 87, 32],\n",
       " 882: [9, 19, 4],\n",
       " 883: [52, 69, 15],\n",
       " 884: [146, 74, 19],\n",
       " 885: [1, 7, 7],\n",
       " 886: [82, 77, 30],\n",
       " 887: [71, 75, 15],\n",
       " 888: [34, 32, 11],\n",
       " 889: [41, 26, 10],\n",
       " 890: [44, 54, 29],\n",
       " 891: [19, 20, 5],\n",
       " 892: [116, 114, 44],\n",
       " 893: [182, 81, 28],\n",
       " 894: [32, 55, 15],\n",
       " 895: [90, 85, 13],\n",
       " 896: [111, 51, 15],\n",
       " 897: [109, 42, 13],\n",
       " 898: [35, 31, 16],\n",
       " 899: [0, 5, 2],\n",
       " 900: [65, 55, 27],\n",
       " 901: [8, 4, 1],\n",
       " 902: [4, 9, 0],\n",
       " 903: [13, 31, 16],\n",
       " 904: [73, 73, 46],\n",
       " 905: [65, 66, 24],\n",
       " 906: [101, 69, 23],\n",
       " 907: [7, 7, 6],\n",
       " 908: [92, 62, 24],\n",
       " 909: [4, 23, 7],\n",
       " 910: [64, 56, 29],\n",
       " 911: [45, 66, 37],\n",
       " 912: [37, 68, 33],\n",
       " 913: [5, 9, 2],\n",
       " 914: [42, 52, 16],\n",
       " 915: [26, 49, 17],\n",
       " 916: [13, 30, 16],\n",
       " 917: [24, 33, 12],\n",
       " 918: [60, 32, 15],\n",
       " 920: [3, 2, 2],\n",
       " 921: [34, 16, 3],\n",
       " 922: [8, 21, 9],\n",
       " 923: [9, 12, 5],\n",
       " 924: [6, 6, 7],\n",
       " 925: [34, 61, 29],\n",
       " 926: [78, 76, 37],\n",
       " 927: [2, 6, 5],\n",
       " 928: [132, 81, 24],\n",
       " 929: [127, 59, 22],\n",
       " 930: [25, 24, 11],\n",
       " 931: [1, 0, 0],\n",
       " 932: [83, 43, 28],\n",
       " 933: [13, 14, 4],\n",
       " 934: [148, 54, 22],\n",
       " 935: [189, 81, 42],\n",
       " 936: [18, 30, 9],\n",
       " 937: [90, 73, 19],\n",
       " 938: [17, 40, 26],\n",
       " 939: [3, 3, 5],\n",
       " 940: [23, 34, 25],\n",
       " 941: [142, 55, 12],\n",
       " 942: [38, 36, 13],\n",
       " 943: [12, 18, 2],\n",
       " 944: [119, 49, 32],\n",
       " 945: [60, 49, 18],\n",
       " 946: [169, 75, 30],\n",
       " 947: [11, 3, 6],\n",
       " 948: [50, 35, 21],\n",
       " 949: [46, 36, 13],\n",
       " 950: [20, 22, 3],\n",
       " 951: [89, 43, 13],\n",
       " 952: [1, 2, 5],\n",
       " 953: [119, 66, 13],\n",
       " 954: [31, 14, 3],\n",
       " 955: [17, 12, 3],\n",
       " 956: [44, 55, 34],\n",
       " 957: [6, 2, 0],\n",
       " 958: [1, 1, 0],\n",
       " 959: [135, 65, 30],\n",
       " 960: [4, 9, 4],\n",
       " 961: [20, 17, 12],\n",
       " 962: [61, 63, 30],\n",
       " 963: [62, 68, 19],\n",
       " 964: [84, 43, 20],\n",
       " 965: [22, 8, 2],\n",
       " 966: [3, 2, 0],\n",
       " 967: [11, 22, 4],\n",
       " 968: [1, 0, 0],\n",
       " 969: [2, 4, 3],\n",
       " 970: [0, 0, 1],\n",
       " 971: [121, 64, 30],\n",
       " 972: [35, 44, 26],\n",
       " 973: [3, 4, 3],\n",
       " 974: [1, 1, 0],\n",
       " 976: [23, 24, 6],\n",
       " 977: [21, 19, 8],\n",
       " 978: [70, 55, 12],\n",
       " 979: [31, 33, 9],\n",
       " 980: [2, 0, 0],\n",
       " 981: [0, 3, 2],\n",
       " 982: [70, 55, 20],\n",
       " 983: [41, 14, 6],\n",
       " 984: [67, 37, 12],\n",
       " 986: [13, 10, 3],\n",
       " 987: [7, 22, 19],\n",
       " 988: [54, 32, 6],\n",
       " 990: [10, 7, 4],\n",
       " 991: [2, 12, 4],\n",
       " 992: [13, 16, 6],\n",
       " 993: [10, 16, 2],\n",
       " 994: [1, 3, 0],\n",
       " 995: [1, 13, 2],\n",
       " 997: [7, 13, 4],\n",
       " 998: [17, 11, 5]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = XX.sort_values(by=[\"item\"], ascending=True)\n",
    "dictItem = {}\n",
    "for i, row in XX.iterrows():\n",
    "    rating = row[\"rating\"]\n",
    "    item = row[\"item\"]\n",
    "    \n",
    "    try:\n",
    "        keyValue = dictItem[item]\n",
    "    except KeyError:\n",
    "        keyValue = [0,0,0]\n",
    "    if(rating == 1):\n",
    "        keyValue[0] = keyValue[0] + 1\n",
    "        dictItem[item] = keyValue\n",
    "        \n",
    "    elif(rating == 0):\n",
    "        keyValue[1] = keyValue[1] + 1\n",
    "        dictItem[item] = keyValue\n",
    "        \n",
    "    elif(rating == -1):\n",
    "        keyValue[2] = keyValue[2] + 1\n",
    "        dictItem[item] = keyValue\n",
    "        \n",
    "dictItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169c965e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 1,\n",
       " 5: 0,\n",
       " 6: 0,\n",
       " 7: 1,\n",
       " 8: 1,\n",
       " 9: -1,\n",
       " 10: 1,\n",
       " 11: 0,\n",
       " 12: 1,\n",
       " 13: 1,\n",
       " 14: 1,\n",
       " 15: 1,\n",
       " 16: 1,\n",
       " 17: -1,\n",
       " 18: 0,\n",
       " 19: 1,\n",
       " 20: 0,\n",
       " 21: 1,\n",
       " 22: 0,\n",
       " 23: -1,\n",
       " 24: 0,\n",
       " 25: 0,\n",
       " 26: 0,\n",
       " 27: 0,\n",
       " 28: 0,\n",
       " 29: 0,\n",
       " 30: 1,\n",
       " 31: 1,\n",
       " 32: 1,\n",
       " 33: 1,\n",
       " 34: 1,\n",
       " 35: 0,\n",
       " 36: 1,\n",
       " 37: -1,\n",
       " 38: -1,\n",
       " 39: 0,\n",
       " 40: 1,\n",
       " 41: -1,\n",
       " 42: -1,\n",
       " 43: 0,\n",
       " 44: 1,\n",
       " 45: -1,\n",
       " 46: 1,\n",
       " 47: 0,\n",
       " 48: -1,\n",
       " 49: 0,\n",
       " 50: -1,\n",
       " 51: 0,\n",
       " 52: 0,\n",
       " 53: 1,\n",
       " 54: 1,\n",
       " 55: 1,\n",
       " 56: 0,\n",
       " 57: 1,\n",
       " 58: 1,\n",
       " 59: 1,\n",
       " 60: 0,\n",
       " 61: 1,\n",
       " 62: -1,\n",
       " 63: 0,\n",
       " 64: 1,\n",
       " 65: 0,\n",
       " 66: 0,\n",
       " 67: 0,\n",
       " 68: 1,\n",
       " 69: 1,\n",
       " 70: 0,\n",
       " 71: 1,\n",
       " 72: 1,\n",
       " 73: 0,\n",
       " 74: 0,\n",
       " 75: 0,\n",
       " 76: 1,\n",
       " 77: 0,\n",
       " 78: 1,\n",
       " 79: -1,\n",
       " 80: 0,\n",
       " 81: 0,\n",
       " 82: -1,\n",
       " 83: 1,\n",
       " 84: 0,\n",
       " 85: 1,\n",
       " 86: -1,\n",
       " 87: 0,\n",
       " 88: 1,\n",
       " 89: 1,\n",
       " 90: -1,\n",
       " 91: 1,\n",
       " 92: 0,\n",
       " 93: 1,\n",
       " 94: 0,\n",
       " 95: 1,\n",
       " 96: 0,\n",
       " 97: 1,\n",
       " 98: 1,\n",
       " 99: 1,\n",
       " 100: 1,\n",
       " 101: 0,\n",
       " 102: 0,\n",
       " 103: 1,\n",
       " 104: 1,\n",
       " 105: 1,\n",
       " 106: 0,\n",
       " 107: 1,\n",
       " 108: 0,\n",
       " 109: 1,\n",
       " 110: 1,\n",
       " 111: 0,\n",
       " 112: 1,\n",
       " 113: 1,\n",
       " 114: 1,\n",
       " 115: 0,\n",
       " 116: 1,\n",
       " 117: 1,\n",
       " 118: 1,\n",
       " 119: 0,\n",
       " 120: 1,\n",
       " 121: 0,\n",
       " 122: 1,\n",
       " 123: 1,\n",
       " 124: 1,\n",
       " 125: -1,\n",
       " 126: 1,\n",
       " 127: 0,\n",
       " 128: -1,\n",
       " 129: -1,\n",
       " 130: 0,\n",
       " 131: 0,\n",
       " 132: -1,\n",
       " 133: 1,\n",
       " 134: 1,\n",
       " 135: 1,\n",
       " 136: 0,\n",
       " 137: 1,\n",
       " 138: 1,\n",
       " 139: 1,\n",
       " 140: -1,\n",
       " 141: 0,\n",
       " 142: 0,\n",
       " 143: 0,\n",
       " 144: -1,\n",
       " 145: -1,\n",
       " 146: -1,\n",
       " 147: 0,\n",
       " 148: 1,\n",
       " 149: -1,\n",
       " 150: 1,\n",
       " 151: 1,\n",
       " 152: 1,\n",
       " 153: 1,\n",
       " 154: 1,\n",
       " 155: 1,\n",
       " 156: 1,\n",
       " 157: 1,\n",
       " 158: 1,\n",
       " 159: 1,\n",
       " 160: 1,\n",
       " 161: 1,\n",
       " 162: 1,\n",
       " 163: 1,\n",
       " 164: 0,\n",
       " 165: 1,\n",
       " 166: 1,\n",
       " 167: 1,\n",
       " 168: 0,\n",
       " 169: 0,\n",
       " 170: 1,\n",
       " 171: 1,\n",
       " 172: 1,\n",
       " 173: 0,\n",
       " 174: 1,\n",
       " 175: 1,\n",
       " 176: 1,\n",
       " 177: 1,\n",
       " 178: 1,\n",
       " 179: 1,\n",
       " 180: 1,\n",
       " 181: 1,\n",
       " 182: 1,\n",
       " 183: 1,\n",
       " 184: 1,\n",
       " 185: 0,\n",
       " 186: -1,\n",
       " 187: 1,\n",
       " 188: 1,\n",
       " 189: 1,\n",
       " 190: 1,\n",
       " 191: 1,\n",
       " 192: 1,\n",
       " 193: 1,\n",
       " 194: 1,\n",
       " 195: 1,\n",
       " 196: 1,\n",
       " 197: 1,\n",
       " 198: 1,\n",
       " 199: 1,\n",
       " 200: 1,\n",
       " 201: 1,\n",
       " 202: 1,\n",
       " 203: 1,\n",
       " 204: 1,\n",
       " 205: 1,\n",
       " 206: 1,\n",
       " 207: 1,\n",
       " 208: 1,\n",
       " 209: 1,\n",
       " 210: 1,\n",
       " 211: 1,\n",
       " 212: 1,\n",
       " 213: 1,\n",
       " 214: 1,\n",
       " 215: 1,\n",
       " 216: 1,\n",
       " 217: 1,\n",
       " 218: 1,\n",
       " 219: 1,\n",
       " 220: 1,\n",
       " 221: 1,\n",
       " 222: 1,\n",
       " 223: 1,\n",
       " 224: 1,\n",
       " 225: 1,\n",
       " 226: 1,\n",
       " 227: 1,\n",
       " 228: 1,\n",
       " 229: 0,\n",
       " 230: 1,\n",
       " 231: 1,\n",
       " 232: 1,\n",
       " 233: 1,\n",
       " 234: 1,\n",
       " 235: 0,\n",
       " 236: 0,\n",
       " 237: 1,\n",
       " 238: 1,\n",
       " 239: 1,\n",
       " 240: -1,\n",
       " 241: 0,\n",
       " 242: 0,\n",
       " 243: 1,\n",
       " 244: 1,\n",
       " 245: 0,\n",
       " 246: -1,\n",
       " 247: 0,\n",
       " 248: 1,\n",
       " 249: 1,\n",
       " 250: 0,\n",
       " 251: 0,\n",
       " 252: 0,\n",
       " 253: 0,\n",
       " 254: 0,\n",
       " 255: 0,\n",
       " 256: 1,\n",
       " 257: -1,\n",
       " 258: 1,\n",
       " 259: 0,\n",
       " 260: -1,\n",
       " 261: 0,\n",
       " 262: 1,\n",
       " 263: 1,\n",
       " 264: 0,\n",
       " 265: -1,\n",
       " 266: 0,\n",
       " 267: -1,\n",
       " 268: 0,\n",
       " 269: 1,\n",
       " 270: 1,\n",
       " 271: 0,\n",
       " 272: 1,\n",
       " 273: 1,\n",
       " 274: 1,\n",
       " 275: 1,\n",
       " 276: 1,\n",
       " 277: 1,\n",
       " 278: 1,\n",
       " 279: 0,\n",
       " 280: 1,\n",
       " 281: 1,\n",
       " 282: 1,\n",
       " 283: 0,\n",
       " 284: 1,\n",
       " 285: 1,\n",
       " 286: 0,\n",
       " 287: 1,\n",
       " 288: 1,\n",
       " 289: 1,\n",
       " 290: 1,\n",
       " 291: 1,\n",
       " 292: 0,\n",
       " 293: -1,\n",
       " 294: 0,\n",
       " 295: -1,\n",
       " 296: -1,\n",
       " 297: 0,\n",
       " 298: 0,\n",
       " 299: 0,\n",
       " 300: 0,\n",
       " 301: 1,\n",
       " 302: 1,\n",
       " 303: 1,\n",
       " 304: 1,\n",
       " 305: 1,\n",
       " 306: 1,\n",
       " 307: 1,\n",
       " 308: 0,\n",
       " 309: 0,\n",
       " 310: 0,\n",
       " 311: 0,\n",
       " 312: 0,\n",
       " 313: 1,\n",
       " 314: 1,\n",
       " 315: 0,\n",
       " 316: 1,\n",
       " 317: 0,\n",
       " 318: 0,\n",
       " 319: 0,\n",
       " 320: -1,\n",
       " 321: 0,\n",
       " 322: 1,\n",
       " 323: 1,\n",
       " 324: 1,\n",
       " 325: 1,\n",
       " 326: 0,\n",
       " 327: 0,\n",
       " 328: 0,\n",
       " 329: -1,\n",
       " 330: 1,\n",
       " 331: 1,\n",
       " 332: 1,\n",
       " 333: 1,\n",
       " 334: 0,\n",
       " 335: -1,\n",
       " 336: 1,\n",
       " 337: 1,\n",
       " 338: 1,\n",
       " 339: 1,\n",
       " 340: 1,\n",
       " 341: 0,\n",
       " 342: 1,\n",
       " 343: 1,\n",
       " 344: 0,\n",
       " 345: -1,\n",
       " 346: 1,\n",
       " 347: 1,\n",
       " 348: 1,\n",
       " 349: 0,\n",
       " 350: 0,\n",
       " 351: 1,\n",
       " 352: 1,\n",
       " 353: 1,\n",
       " 354: 1,\n",
       " 355: 1,\n",
       " 356: 1,\n",
       " 357: 1,\n",
       " 358: 1,\n",
       " 359: -1,\n",
       " 360: 0,\n",
       " 361: 1,\n",
       " 362: -1,\n",
       " 363: -1,\n",
       " 364: 0,\n",
       " 365: 1,\n",
       " 366: 1,\n",
       " 367: 0,\n",
       " 368: 1,\n",
       " 369: 0,\n",
       " 370: 0,\n",
       " 371: 1,\n",
       " 372: 0,\n",
       " 373: 0,\n",
       " 374: 0,\n",
       " 375: 0,\n",
       " 376: 0,\n",
       " 377: 0,\n",
       " 378: 1,\n",
       " 379: 0,\n",
       " 380: 0,\n",
       " 381: 0,\n",
       " 382: 0,\n",
       " 383: -1,\n",
       " 384: -1,\n",
       " 385: 0,\n",
       " 386: 1,\n",
       " 387: -1,\n",
       " 388: 1,\n",
       " 389: 1,\n",
       " 390: 0,\n",
       " 391: 0,\n",
       " 392: 1,\n",
       " 393: 0,\n",
       " 394: 0,\n",
       " 395: 0,\n",
       " 396: 1,\n",
       " 397: 0,\n",
       " 398: 1,\n",
       " 399: 1,\n",
       " 400: 1,\n",
       " 401: -1,\n",
       " 402: 1,\n",
       " 403: 0,\n",
       " 404: 0,\n",
       " 405: 1,\n",
       " 406: 0,\n",
       " 407: 1,\n",
       " 408: 1,\n",
       " 409: 1,\n",
       " 410: 1,\n",
       " 411: -1,\n",
       " 412: 1,\n",
       " 413: 0,\n",
       " 414: 0,\n",
       " 415: 1,\n",
       " 416: 0,\n",
       " 417: 0,\n",
       " 418: 1,\n",
       " 419: -1,\n",
       " 420: 0,\n",
       " 421: 1,\n",
       " 422: 1,\n",
       " 423: -1,\n",
       " 424: 1,\n",
       " 425: 1,\n",
       " 426: 1,\n",
       " 427: -1,\n",
       " 428: 1,\n",
       " 429: -1,\n",
       " 430: 1,\n",
       " 431: 0,\n",
       " 432: 1,\n",
       " 433: 0,\n",
       " 434: 1,\n",
       " 435: 1,\n",
       " 436: 1,\n",
       " 437: 0,\n",
       " 438: 1,\n",
       " 439: 1,\n",
       " 440: 1,\n",
       " 441: 0,\n",
       " 442: 0,\n",
       " 443: 1,\n",
       " 444: 1,\n",
       " 445: 1,\n",
       " 446: 1,\n",
       " 447: 1,\n",
       " 448: 0,\n",
       " 449: 1,\n",
       " 450: 0,\n",
       " 451: 1,\n",
       " 452: 1,\n",
       " 453: 0,\n",
       " 454: 1,\n",
       " 455: -1,\n",
       " 456: 1,\n",
       " 457: 1,\n",
       " 458: 0,\n",
       " 459: 1,\n",
       " 460: -1,\n",
       " 461: 0,\n",
       " 462: 1,\n",
       " 463: 1,\n",
       " 464: 1,\n",
       " 465: -1,\n",
       " 466: -1,\n",
       " 467: 1,\n",
       " 468: 1,\n",
       " 469: 1,\n",
       " 470: 1,\n",
       " 471: 1,\n",
       " 472: 1,\n",
       " 473: 1,\n",
       " 474: -1,\n",
       " 475: 1,\n",
       " 476: 1,\n",
       " 477: 1,\n",
       " 478: 1,\n",
       " 479: 1,\n",
       " 480: 1,\n",
       " 481: 1,\n",
       " 482: 1,\n",
       " 483: 0,\n",
       " 484: 1,\n",
       " 485: -1,\n",
       " 486: 1,\n",
       " 487: 0,\n",
       " 488: 0,\n",
       " 489: 0,\n",
       " 490: 0,\n",
       " 491: 1,\n",
       " 492: 1,\n",
       " 493: 0,\n",
       " 494: 1,\n",
       " 495: 1,\n",
       " 496: 1,\n",
       " 497: 0,\n",
       " 498: 1,\n",
       " 499: 1,\n",
       " 500: 1,\n",
       " 501: 0,\n",
       " 502: 0,\n",
       " 503: 0,\n",
       " 504: 0,\n",
       " 505: -1,\n",
       " 506: 0,\n",
       " 507: 0,\n",
       " 508: 1,\n",
       " 509: 1,\n",
       " 510: 0,\n",
       " 511: -1,\n",
       " 512: 0,\n",
       " 513: 1,\n",
       " 514: 1,\n",
       " 515: 1,\n",
       " 516: -1,\n",
       " 517: 1,\n",
       " 518: -1,\n",
       " 519: -1,\n",
       " 520: -1,\n",
       " 521: 1,\n",
       " 522: -1,\n",
       " 523: 0,\n",
       " 524: 1,\n",
       " 525: 1,\n",
       " 526: 1,\n",
       " 527: 1,\n",
       " 528: -1,\n",
       " 529: 0,\n",
       " 530: 0,\n",
       " 531: 1,\n",
       " 532: 0,\n",
       " 533: 1,\n",
       " 534: 0,\n",
       " 535: 1,\n",
       " 536: 1,\n",
       " 537: 0,\n",
       " 538: 0,\n",
       " 539: 0,\n",
       " 540: 1,\n",
       " 541: 1,\n",
       " 542: -1,\n",
       " 543: 1,\n",
       " 544: 1,\n",
       " 545: 0,\n",
       " 546: 1,\n",
       " 547: 1,\n",
       " 548: -1,\n",
       " 549: 0,\n",
       " 550: -1,\n",
       " 551: 1,\n",
       " 552: 1,\n",
       " 553: 1,\n",
       " 554: 1,\n",
       " 555: 1,\n",
       " 556: -1,\n",
       " 557: -1,\n",
       " 558: 1,\n",
       " 559: 1,\n",
       " 560: 0,\n",
       " 561: 0,\n",
       " 562: 0,\n",
       " 563: 0,\n",
       " 564: -1,\n",
       " 565: 1,\n",
       " 566: 1,\n",
       " 567: 0,\n",
       " 568: 0,\n",
       " 569: 1,\n",
       " 570: -1,\n",
       " 571: 1,\n",
       " 572: 0,\n",
       " 573: 1,\n",
       " 574: 0,\n",
       " 575: 1,\n",
       " 576: 0,\n",
       " 577: 1,\n",
       " 578: 1,\n",
       " 579: 1,\n",
       " 580: 1,\n",
       " 581: 1,\n",
       " 582: 1,\n",
       " 583: 1,\n",
       " 584: 1,\n",
       " 585: 0,\n",
       " 586: 1,\n",
       " 587: -1,\n",
       " 588: 0,\n",
       " 589: 1,\n",
       " 590: 1,\n",
       " 591: 0,\n",
       " 592: 1,\n",
       " 593: 1,\n",
       " 594: 1,\n",
       " 595: 1,\n",
       " 596: 1,\n",
       " 597: 1,\n",
       " 598: 1,\n",
       " 599: 0,\n",
       " 600: -1,\n",
       " 601: 0,\n",
       " 602: 0,\n",
       " 603: 0,\n",
       " 604: 0,\n",
       " 605: 1,\n",
       " 606: 0,\n",
       " 607: 0,\n",
       " 608: 0,\n",
       " 609: 0,\n",
       " 610: 1,\n",
       " 611: -1,\n",
       " 612: 1,\n",
       " 613: 0,\n",
       " 614: 0,\n",
       " 615: 0,\n",
       " 616: 0,\n",
       " 617: 1,\n",
       " 618: 0,\n",
       " 619: 1,\n",
       " 620: 1,\n",
       " 621: 1,\n",
       " 622: 0,\n",
       " 623: 0,\n",
       " 624: 1,\n",
       " 625: 1,\n",
       " 626: 1,\n",
       " 627: 0,\n",
       " 628: 1,\n",
       " 629: 1,\n",
       " 630: -1,\n",
       " 631: 0,\n",
       " 632: 1,\n",
       " 633: 1,\n",
       " 634: 1,\n",
       " 635: 1,\n",
       " 636: 1,\n",
       " 637: 1,\n",
       " 638: 1,\n",
       " 639: -1,\n",
       " 640: 1,\n",
       " 641: 1,\n",
       " 642: 0,\n",
       " 643: 1,\n",
       " 644: 1,\n",
       " 645: 1,\n",
       " 646: 0,\n",
       " 647: 0,\n",
       " 648: 1,\n",
       " 649: 0,\n",
       " 650: 1,\n",
       " 651: 1,\n",
       " 652: 0,\n",
       " 653: 1,\n",
       " 654: -1,\n",
       " 655: 0,\n",
       " 656: 0,\n",
       " 657: 1,\n",
       " 658: 1,\n",
       " 659: -1,\n",
       " 660: -1,\n",
       " 661: 0,\n",
       " 662: 1,\n",
       " 663: 1,\n",
       " 664: -1,\n",
       " 665: 1,\n",
       " 666: 1,\n",
       " 667: 0,\n",
       " 668: 0,\n",
       " 669: 1,\n",
       " 670: 1,\n",
       " 671: 1,\n",
       " 672: 0,\n",
       " 673: -1,\n",
       " 674: 0,\n",
       " 675: 1,\n",
       " 676: 1,\n",
       " 677: 0,\n",
       " 678: 1,\n",
       " 679: 1,\n",
       " 680: 1,\n",
       " 681: 1,\n",
       " 682: 1,\n",
       " 683: 1,\n",
       " 684: 0,\n",
       " 685: 0,\n",
       " 686: 1,\n",
       " 687: 0,\n",
       " 688: 1,\n",
       " 689: 1,\n",
       " 690: -1,\n",
       " 691: 1,\n",
       " 692: 1,\n",
       " 693: 0,\n",
       " 694: 0,\n",
       " 695: 0,\n",
       " 696: 1,\n",
       " 697: 1,\n",
       " 698: 1,\n",
       " 699: 1,\n",
       " 700: -1,\n",
       " 701: 1,\n",
       " 702: 0,\n",
       " 703: 1,\n",
       " 704: 1,\n",
       " 705: 1,\n",
       " 706: 1,\n",
       " 707: 1,\n",
       " 708: 0,\n",
       " 709: 0,\n",
       " 710: 1,\n",
       " 711: 1,\n",
       " 712: 0,\n",
       " 713: 0,\n",
       " 714: -1,\n",
       " 715: 0,\n",
       " 716: 1,\n",
       " 717: 0,\n",
       " 718: 1,\n",
       " 719: 1,\n",
       " 720: 1,\n",
       " 721: 1,\n",
       " 722: 0,\n",
       " 723: -1,\n",
       " 724: 0,\n",
       " 725: 0,\n",
       " 726: 1,\n",
       " 727: 1,\n",
       " 728: 0,\n",
       " 729: 0,\n",
       " 730: 1,\n",
       " 731: 0,\n",
       " 732: 1,\n",
       " 733: 1,\n",
       " 734: 1,\n",
       " 735: 1,\n",
       " 736: 1,\n",
       " 737: 0,\n",
       " 738: 0,\n",
       " 739: 1,\n",
       " 740: 0,\n",
       " 741: 0,\n",
       " 742: 1,\n",
       " 743: 0,\n",
       " 744: 1,\n",
       " 745: 0,\n",
       " 746: 0,\n",
       " 747: 0,\n",
       " 748: 1,\n",
       " 749: 0,\n",
       " 750: 1,\n",
       " 751: -1,\n",
       " 752: 1,\n",
       " 753: 0,\n",
       " 754: 1,\n",
       " 755: 1,\n",
       " 756: -1,\n",
       " 757: 1,\n",
       " 758: -1,\n",
       " 759: 0,\n",
       " 760: 1,\n",
       " 761: 0,\n",
       " 762: 0,\n",
       " 763: 1,\n",
       " 764: 1,\n",
       " 765: 1,\n",
       " 766: 0,\n",
       " 767: 0,\n",
       " 768: 0,\n",
       " 769: 0,\n",
       " 770: 0,\n",
       " 771: 0,\n",
       " 772: 0,\n",
       " 773: 0,\n",
       " 774: 1,\n",
       " 775: 1,\n",
       " 776: 0,\n",
       " 777: 0,\n",
       " 778: 1,\n",
       " 779: 1,\n",
       " 780: 1,\n",
       " 781: 0,\n",
       " 782: 0,\n",
       " 783: 1,\n",
       " 784: 1,\n",
       " 785: -1,\n",
       " 786: 1,\n",
       " 787: -1,\n",
       " 788: 0,\n",
       " 789: 0,\n",
       " 790: 0,\n",
       " 791: -1,\n",
       " 792: 0,\n",
       " 793: 0,\n",
       " 794: 0,\n",
       " 795: 1,\n",
       " 796: 0,\n",
       " 797: 0,\n",
       " 798: 1,\n",
       " 799: -1,\n",
       " 800: 0,\n",
       " 801: 0,\n",
       " 802: 1,\n",
       " 803: 1,\n",
       " 804: 1,\n",
       " 805: 0,\n",
       " 806: 0,\n",
       " 807: 1,\n",
       " 808: 1,\n",
       " 809: 0,\n",
       " 810: 0,\n",
       " 811: 0,\n",
       " 812: -1,\n",
       " 813: 1,\n",
       " 814: 1,\n",
       " 815: 1,\n",
       " 816: 1,\n",
       " 817: 1,\n",
       " 818: 1,\n",
       " 819: 0,\n",
       " 820: 1,\n",
       " 821: 0,\n",
       " 822: 0,\n",
       " 823: 0,\n",
       " 824: 1,\n",
       " 825: 0,\n",
       " 826: 1,\n",
       " 827: 1,\n",
       " 828: -1,\n",
       " 829: 1,\n",
       " 830: 1,\n",
       " 831: 1,\n",
       " 832: 0,\n",
       " 833: 0,\n",
       " 834: 0,\n",
       " 835: 1,\n",
       " 836: 0,\n",
       " 837: 1,\n",
       " 838: 0,\n",
       " 839: 1,\n",
       " 840: 0,\n",
       " 841: -1,\n",
       " 842: 1,\n",
       " 843: 1,\n",
       " 844: 1,\n",
       " 845: 0,\n",
       " 846: 0,\n",
       " 847: 1,\n",
       " 848: 1,\n",
       " 849: 0,\n",
       " 850: 1,\n",
       " 851: 0,\n",
       " 852: 0,\n",
       " 853: 0,\n",
       " 854: 1,\n",
       " 855: 0,\n",
       " 856: 0,\n",
       " 857: 1,\n",
       " 858: 1,\n",
       " 859: 0,\n",
       " 860: 0,\n",
       " 861: 0,\n",
       " 862: 1,\n",
       " 863: 0,\n",
       " 864: 1,\n",
       " 865: 0,\n",
       " 866: 0,\n",
       " 867: 1,\n",
       " 868: 0,\n",
       " 869: 1,\n",
       " 870: 1,\n",
       " 871: 1,\n",
       " 872: 1,\n",
       " 873: 0,\n",
       " 874: 0,\n",
       " 875: 1,\n",
       " 876: 1,\n",
       " 877: 1,\n",
       " 878: 0,\n",
       " 879: 1,\n",
       " 880: 0,\n",
       " 881: 1,\n",
       " 882: 0,\n",
       " 883: 0,\n",
       " 884: 1,\n",
       " 885: 0,\n",
       " 886: 1,\n",
       " 887: 0,\n",
       " 888: 1,\n",
       " 889: 1,\n",
       " 890: 0,\n",
       " 891: 0,\n",
       " 892: 1,\n",
       " 893: 1,\n",
       " 894: 0,\n",
       " 895: 1,\n",
       " 896: 1,\n",
       " 897: 1,\n",
       " 898: 1,\n",
       " 899: 0,\n",
       " 900: 1,\n",
       " 901: 1,\n",
       " 902: 0,\n",
       " 903: 0,\n",
       " 904: 1,\n",
       " 905: 0,\n",
       " 906: 1,\n",
       " 907: 1,\n",
       " 908: 1,\n",
       " 909: 0,\n",
       " 910: 1,\n",
       " 911: 0,\n",
       " 912: 0,\n",
       " 913: 0,\n",
       " 914: 0,\n",
       " 915: 0,\n",
       " 916: 0,\n",
       " 917: 0,\n",
       " 918: 1,\n",
       " 920: 1,\n",
       " 921: 1,\n",
       " 922: 0,\n",
       " 923: 0,\n",
       " 924: -1,\n",
       " 925: 0,\n",
       " 926: 1,\n",
       " 927: 0,\n",
       " 928: 1,\n",
       " 929: 1,\n",
       " 930: 1,\n",
       " 931: 1,\n",
       " 932: 1,\n",
       " 933: 0,\n",
       " 934: 1,\n",
       " 935: 1,\n",
       " 936: 0,\n",
       " 937: 1,\n",
       " 938: 0,\n",
       " 939: -1,\n",
       " 940: 0,\n",
       " 941: 1,\n",
       " 942: 1,\n",
       " 943: 0,\n",
       " 944: 1,\n",
       " 945: 1,\n",
       " 946: 1,\n",
       " 947: 1,\n",
       " 948: 1,\n",
       " 949: 1,\n",
       " 950: 0,\n",
       " 951: 1,\n",
       " 952: -1,\n",
       " 953: 1,\n",
       " 954: 1,\n",
       " 955: 1,\n",
       " 956: 0,\n",
       " 957: 1,\n",
       " 958: 1,\n",
       " 959: 1,\n",
       " 960: 0,\n",
       " 961: 1,\n",
       " 962: 0,\n",
       " 963: 0,\n",
       " 964: 1,\n",
       " 965: 1,\n",
       " 966: 1,\n",
       " 967: 0,\n",
       " 968: 1,\n",
       " 969: 0,\n",
       " 970: -1,\n",
       " 971: 1,\n",
       " 972: 0,\n",
       " 973: 0,\n",
       " 974: 1,\n",
       " 976: 0,\n",
       " 977: 1,\n",
       " 978: 1,\n",
       " 979: 0,\n",
       " 980: 1,\n",
       " 981: 0,\n",
       " 982: 1,\n",
       " 983: 1,\n",
       " 984: 1,\n",
       " 986: 1,\n",
       " 987: 0,\n",
       " 988: 1,\n",
       " 990: 1,\n",
       " 991: 0,\n",
       " 992: 0,\n",
       " 993: 0,\n",
       " 994: 0,\n",
       " 995: 0,\n",
       " 997: 0,\n",
       " 998: 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in dictItem:\n",
    "    itemValue = dictItem[i]\n",
    "    largestIdx = itemValue.index(max(itemValue))\n",
    "    if(largestIdx == 0): \n",
    "        dictItem[i] = 1\n",
    "    if(largestIdx == 1): \n",
    "        dictItem[i] = 0\n",
    "    if(largestIdx == 2): \n",
    "        dictItem[i] = -1\n",
    "dictItem   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd327237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 64,\n",
       " 1: 19,\n",
       " 2: 64,\n",
       " 3: 69,\n",
       " 4: 66,\n",
       " 5: 12,\n",
       " 6: 90,\n",
       " 7: 550,\n",
       " 8: 76,\n",
       " 9: 6,\n",
       " 10: 257,\n",
       " 11: 63,\n",
       " 12: 72,\n",
       " 13: 83,\n",
       " 14: 277,\n",
       " 15: 270,\n",
       " 16: 58,\n",
       " 17: 43,\n",
       " 18: 23,\n",
       " 19: 107,\n",
       " 20: 71,\n",
       " 21: 32,\n",
       " 22: 118,\n",
       " 23: 47,\n",
       " 24: 86,\n",
       " 25: 6,\n",
       " 26: 29,\n",
       " 27: 67,\n",
       " 28: 70,\n",
       " 29: 32,\n",
       " 30: 59,\n",
       " 31: 60,\n",
       " 32: 69,\n",
       " 33: 25,\n",
       " 34: 48,\n",
       " 35: 34,\n",
       " 36: 130,\n",
       " 37: 94,\n",
       " 38: 101,\n",
       " 39: 105,\n",
       " 40: 185,\n",
       " 41: 37,\n",
       " 42: 114,\n",
       " 43: 221,\n",
       " 44: 25,\n",
       " 45: 176,\n",
       " 46: 68,\n",
       " 47: 119,\n",
       " 48: 91,\n",
       " 49: 7,\n",
       " 50: 32,\n",
       " 51: 14,\n",
       " 52: 39,\n",
       " 53: 48,\n",
       " 54: 16,\n",
       " 55: 187,\n",
       " 56: 398,\n",
       " 57: 275,\n",
       " 58: 173,\n",
       " 59: 24,\n",
       " 60: 43,\n",
       " 61: 122,\n",
       " 62: 173,\n",
       " 63: 96,\n",
       " 64: 16,\n",
       " 65: 67,\n",
       " 66: 73,\n",
       " 67: 11,\n",
       " 68: 125,\n",
       " 69: 119,\n",
       " 70: 6,\n",
       " 71: 117,\n",
       " 72: 55,\n",
       " 73: 78,\n",
       " 74: 114,\n",
       " 75: 52,\n",
       " 76: 49,\n",
       " 77: 32,\n",
       " 78: 38,\n",
       " 79: 43,\n",
       " 80: 12,\n",
       " 81: 142,\n",
       " 82: 33,\n",
       " 83: 50,\n",
       " 84: 11,\n",
       " 85: 33,\n",
       " 86: 36,\n",
       " 87: 46,\n",
       " 88: 8,\n",
       " 89: 159,\n",
       " 90: 48,\n",
       " 91: 173,\n",
       " 92: 217,\n",
       " 93: 75,\n",
       " 94: 8,\n",
       " 95: 8,\n",
       " 96: 67,\n",
       " 97: 68,\n",
       " 98: 141,\n",
       " 99: 52,\n",
       " 100: 33,\n",
       " 101: 129,\n",
       " 102: 8,\n",
       " 103: 75,\n",
       " 104: 46,\n",
       " 105: 198,\n",
       " 106: 84,\n",
       " 107: 80,\n",
       " 108: 126,\n",
       " 109: 53,\n",
       " 110: 82,\n",
       " 111: 15,\n",
       " 112: 76,\n",
       " 113: 19,\n",
       " 114: 124,\n",
       " 115: 67,\n",
       " 116: 46,\n",
       " 117: 84,\n",
       " 118: 43,\n",
       " 119: 11,\n",
       " 120: 10,\n",
       " 121: 18,\n",
       " 122: 13,\n",
       " 123: 110,\n",
       " 124: 63,\n",
       " 125: 20,\n",
       " 126: 110,\n",
       " 127: 9,\n",
       " 128: 45,\n",
       " 129: 14,\n",
       " 130: 34,\n",
       " 131: 54,\n",
       " 132: 137,\n",
       " 133: 118,\n",
       " 134: 13,\n",
       " 135: 128,\n",
       " 136: 101,\n",
       " 137: 38,\n",
       " 138: 35,\n",
       " 139: 88,\n",
       " 140: 29,\n",
       " 141: 15,\n",
       " 142: 222,\n",
       " 143: 39,\n",
       " 144: 28,\n",
       " 145: 188,\n",
       " 146: 194,\n",
       " 147: 50,\n",
       " 148: 133,\n",
       " 149: 21,\n",
       " 150: 14,\n",
       " 151: 50,\n",
       " 152: 33,\n",
       " 153: 94,\n",
       " 154: 21,\n",
       " 155: 140,\n",
       " 156: 28,\n",
       " 157: 92,\n",
       " 158: 106,\n",
       " 159: 40,\n",
       " 160: 307,\n",
       " 161: 95,\n",
       " 162: 184,\n",
       " 163: 203,\n",
       " 164: 39,\n",
       " 165: 5,\n",
       " 166: 266,\n",
       " 167: 204,\n",
       " 168: 243,\n",
       " 169: 80,\n",
       " 170: 92,\n",
       " 171: 53,\n",
       " 172: 171,\n",
       " 173: 35,\n",
       " 174: 6,\n",
       " 175: 145,\n",
       " 176: 139,\n",
       " 177: 82,\n",
       " 178: 78,\n",
       " 179: 84,\n",
       " 180: 50,\n",
       " 181: 78,\n",
       " 182: 14,\n",
       " 183: 108,\n",
       " 184: 77,\n",
       " 185: 186,\n",
       " 186: 24,\n",
       " 187: 61,\n",
       " 188: 235,\n",
       " 189: 19,\n",
       " 190: 12,\n",
       " 191: 3,\n",
       " 192: 103,\n",
       " 193: 190,\n",
       " 194: 41,\n",
       " 195: 38,\n",
       " 196: 55,\n",
       " 197: 21,\n",
       " 198: 22,\n",
       " 199: 95,\n",
       " 200: 62,\n",
       " 201: 280,\n",
       " 202: 130,\n",
       " 203: 107,\n",
       " 204: 207,\n",
       " 205: 86,\n",
       " 206: 36,\n",
       " 207: 25,\n",
       " 208: 5,\n",
       " 209: 278,\n",
       " 210: 102,\n",
       " 211: 199,\n",
       " 212: 16,\n",
       " 213: 93,\n",
       " 214: 81,\n",
       " 215: 50,\n",
       " 216: 99,\n",
       " 217: 27,\n",
       " 218: 126,\n",
       " 219: 102,\n",
       " 220: 6,\n",
       " 221: 33,\n",
       " 222: 152,\n",
       " 223: 119,\n",
       " 224: 57,\n",
       " 225: 25,\n",
       " 226: 247,\n",
       " 227: 95,\n",
       " 228: 145,\n",
       " 229: 131,\n",
       " 230: 86,\n",
       " 231: 15,\n",
       " 232: 72,\n",
       " 233: 149,\n",
       " 234: 72,\n",
       " 235: 59,\n",
       " 236: 53,\n",
       " 237: 233,\n",
       " 238: 209,\n",
       " 239: 54,\n",
       " 240: 29,\n",
       " 241: 162,\n",
       " 242: 32,\n",
       " 243: 89,\n",
       " 244: 31,\n",
       " 245: 426,\n",
       " 246: 34,\n",
       " 247: 20,\n",
       " 248: 13,\n",
       " 249: 17,\n",
       " 250: 15,\n",
       " 251: 83,\n",
       " 252: 28,\n",
       " 253: 18,\n",
       " 254: 45,\n",
       " 255: 7,\n",
       " 256: 11,\n",
       " 257: 17,\n",
       " 258: 201,\n",
       " 259: 59,\n",
       " 260: 120,\n",
       " 261: 43,\n",
       " 262: 115,\n",
       " 263: 226,\n",
       " 264: 81,\n",
       " 265: 36,\n",
       " 266: 8,\n",
       " 267: 70,\n",
       " 268: 155,\n",
       " 269: 138,\n",
       " 270: 47,\n",
       " 271: 9,\n",
       " 272: 56,\n",
       " 273: 103,\n",
       " 274: 61,\n",
       " 275: 177,\n",
       " 276: 18,\n",
       " 277: 210,\n",
       " 278: 107,\n",
       " 279: 24,\n",
       " 280: 101,\n",
       " 281: 330,\n",
       " 282: 1,\n",
       " 283: 195,\n",
       " 284: 11,\n",
       " 285: 59,\n",
       " 286: 19,\n",
       " 287: 73,\n",
       " 288: 99,\n",
       " 289: 70,\n",
       " 290: 142,\n",
       " 291: 67,\n",
       " 292: 39,\n",
       " 293: 40,\n",
       " 294: 21,\n",
       " 295: 30,\n",
       " 296: 96,\n",
       " 297: 57,\n",
       " 298: 78,\n",
       " 299: 98,\n",
       " 300: 100,\n",
       " 301: 101,\n",
       " 302: 56,\n",
       " 303: 79,\n",
       " 304: 26,\n",
       " 305: 8,\n",
       " 306: 70,\n",
       " 307: 22,\n",
       " 308: 238,\n",
       " 309: 59,\n",
       " 310: 45,\n",
       " 311: 42,\n",
       " 312: 48,\n",
       " 313: 40,\n",
       " 314: 139,\n",
       " 315: 14,\n",
       " 316: 22,\n",
       " 317: 32,\n",
       " 318: 126,\n",
       " 319: 142,\n",
       " 320: 153,\n",
       " 321: 13,\n",
       " 322: 152,\n",
       " 323: 81,\n",
       " 324: 34,\n",
       " 325: 61,\n",
       " 326: 126,\n",
       " 327: 313,\n",
       " 328: 13,\n",
       " 329: 15,\n",
       " 330: 51,\n",
       " 331: 27,\n",
       " 332: 21,\n",
       " 333: 119,\n",
       " 334: 178,\n",
       " 335: 48,\n",
       " 336: 14,\n",
       " 337: 81,\n",
       " 338: 136,\n",
       " 339: 94,\n",
       " 340: 30,\n",
       " 341: 66,\n",
       " 342: 237,\n",
       " 343: 9,\n",
       " 344: 31,\n",
       " 345: 17,\n",
       " 346: 62,\n",
       " 347: 134,\n",
       " 348: 9,\n",
       " 349: 41,\n",
       " 350: 36,\n",
       " 351: 95,\n",
       " 352: 204,\n",
       " 353: 19,\n",
       " 354: 102,\n",
       " 355: 37,\n",
       " 356: 42,\n",
       " 357: 102,\n",
       " 358: 94,\n",
       " 359: 35,\n",
       " 360: 211,\n",
       " 361: 112,\n",
       " 362: 21,\n",
       " 363: 5,\n",
       " 364: 17,\n",
       " 365: 161,\n",
       " 366: 321,\n",
       " 367: 49,\n",
       " 368: 33,\n",
       " 369: 69,\n",
       " 370: 60,\n",
       " 371: 42,\n",
       " 372: 43,\n",
       " 373: 53,\n",
       " 374: 72,\n",
       " 375: 60,\n",
       " 376: 90,\n",
       " 377: 31,\n",
       " 378: 109,\n",
       " 379: 19,\n",
       " 380: 131,\n",
       " 381: 62,\n",
       " 382: 83,\n",
       " 383: 23,\n",
       " 384: 21,\n",
       " 385: 5,\n",
       " 386: 121,\n",
       " 387: 10,\n",
       " 388: 14,\n",
       " 389: 207,\n",
       " 390: 69,\n",
       " 391: 24,\n",
       " 392: 186,\n",
       " 393: 32,\n",
       " 394: 39,\n",
       " 395: 42,\n",
       " 396: 74,\n",
       " 397: 14,\n",
       " 398: 61,\n",
       " 399: 78,\n",
       " 400: 6,\n",
       " 401: 48,\n",
       " 402: 79,\n",
       " 403: 128,\n",
       " 404: 68,\n",
       " 405: 75,\n",
       " 406: 80,\n",
       " 407: 139,\n",
       " 408: 33,\n",
       " 409: 42,\n",
       " 410: 69,\n",
       " 411: 56,\n",
       " 412: 157,\n",
       " 413: 153,\n",
       " 414: 8,\n",
       " 415: 132,\n",
       " 416: 261,\n",
       " 417: 12,\n",
       " 418: 70,\n",
       " 419: 43,\n",
       " 420: 49,\n",
       " 421: 51,\n",
       " 422: 78,\n",
       " 423: 203,\n",
       " 424: 113,\n",
       " 425: 3,\n",
       " 426: 88,\n",
       " 427: 198,\n",
       " 428: 108,\n",
       " 429: 53,\n",
       " 430: 72,\n",
       " 431: 132,\n",
       " 432: 85,\n",
       " 433: 42,\n",
       " 434: 31,\n",
       " 435: 82,\n",
       " 436: 90,\n",
       " 437: 229,\n",
       " 438: 73,\n",
       " 439: 18,\n",
       " 440: 113,\n",
       " 441: 62,\n",
       " 442: 44,\n",
       " 443: 62,\n",
       " 444: 75,\n",
       " 445: 77,\n",
       " 446: 103,\n",
       " 447: 32,\n",
       " 448: 32,\n",
       " 449: 21,\n",
       " 450: 7,\n",
       " 451: 58,\n",
       " 452: 53,\n",
       " 453: 67,\n",
       " 454: 116,\n",
       " 455: 90,\n",
       " 456: 65,\n",
       " 457: 151,\n",
       " 458: 40,\n",
       " 459: 30,\n",
       " 460: 91,\n",
       " 461: 7,\n",
       " 462: 78,\n",
       " 463: 22,\n",
       " 464: 36,\n",
       " 465: 168,\n",
       " 466: 56,\n",
       " 467: 94,\n",
       " 468: 153,\n",
       " 469: 30,\n",
       " 470: 151,\n",
       " 471: 123,\n",
       " 472: 10,\n",
       " 473: 149,\n",
       " 474: 60,\n",
       " 475: 350,\n",
       " 476: 20,\n",
       " 477: 19,\n",
       " 478: 48,\n",
       " 479: 75,\n",
       " 480: 205,\n",
       " 481: 112,\n",
       " 482: 228,\n",
       " 483: 28,\n",
       " 484: 133,\n",
       " 485: 128,\n",
       " 486: 53,\n",
       " 487: 106,\n",
       " 488: 111,\n",
       " 489: 14,\n",
       " 490: 49,\n",
       " 491: 154,\n",
       " 492: 26,\n",
       " 493: 38,\n",
       " 494: 143,\n",
       " 495: 38,\n",
       " 496: 77,\n",
       " 497: 45,\n",
       " 498: 61,\n",
       " 499: 9,\n",
       " 500: 196,\n",
       " 501: 3,\n",
       " 502: 103,\n",
       " 503: 56,\n",
       " 504: 61,\n",
       " 505: 104,\n",
       " 506: 12,\n",
       " 507: 63,\n",
       " 508: 62,\n",
       " 509: 93,\n",
       " 510: 49,\n",
       " 511: 20,\n",
       " 512: 31,\n",
       " 513: 33,\n",
       " 514: 19,\n",
       " 515: 140,\n",
       " 516: 110,\n",
       " 517: 68,\n",
       " 518: 3,\n",
       " 519: 72,\n",
       " 520: 96,\n",
       " 521: 90,\n",
       " 522: 50,\n",
       " 523: 107,\n",
       " 524: 51,\n",
       " 525: 127,\n",
       " 526: 54,\n",
       " 527: 38,\n",
       " 528: 71,\n",
       " 529: 29,\n",
       " 530: 97,\n",
       " 531: 95,\n",
       " 532: 24,\n",
       " 533: 85,\n",
       " 534: 55,\n",
       " 535: 128,\n",
       " 536: 99,\n",
       " 537: 138,\n",
       " 538: 149,\n",
       " 539: 64,\n",
       " 540: 166,\n",
       " 541: 28,\n",
       " 542: 21,\n",
       " 543: 34,\n",
       " 544: 39,\n",
       " 545: 133,\n",
       " 546: 91,\n",
       " 547: 142,\n",
       " 548: 167,\n",
       " 549: 132,\n",
       " 550: 180,\n",
       " 551: 65,\n",
       " 552: 14,\n",
       " 553: 13,\n",
       " 554: 8,\n",
       " 555: 13,\n",
       " 556: 61,\n",
       " 557: 42,\n",
       " 558: 18,\n",
       " 559: 60,\n",
       " 560: 30,\n",
       " 561: 35,\n",
       " 562: 92,\n",
       " 563: 53,\n",
       " 564: 61,\n",
       " 565: 12,\n",
       " 566: 53,\n",
       " 567: 139,\n",
       " 568: 49,\n",
       " 569: 40,\n",
       " 570: 132,\n",
       " 571: 28,\n",
       " 572: 45,\n",
       " 573: 11,\n",
       " 574: 305,\n",
       " 575: 22,\n",
       " 576: 62,\n",
       " 577: 53,\n",
       " 578: 16,\n",
       " 579: 106,\n",
       " 580: 137,\n",
       " 581: 54,\n",
       " 582: 5,\n",
       " 583: 83,\n",
       " 584: 7,\n",
       " 585: 84,\n",
       " 586: 112,\n",
       " 587: 133,\n",
       " 588: 28,\n",
       " 589: 30,\n",
       " 590: 29,\n",
       " 591: 78,\n",
       " 592: 52,\n",
       " 593: 5,\n",
       " 594: 28,\n",
       " 595: 240,\n",
       " 596: 105,\n",
       " 597: 65,\n",
       " 598: 153,\n",
       " 599: 131,\n",
       " 600: 79,\n",
       " 601: 28,\n",
       " 602: 23,\n",
       " 603: 67,\n",
       " 604: 110,\n",
       " 605: 71,\n",
       " 606: 9,\n",
       " 607: 154,\n",
       " 608: 42,\n",
       " 609: 115,\n",
       " 610: 5,\n",
       " 611: 132,\n",
       " 612: 57,\n",
       " 613: 139,\n",
       " 614: 40,\n",
       " 615: 70,\n",
       " 616: 10,\n",
       " 617: 82,\n",
       " 618: 39,\n",
       " 619: 22,\n",
       " 620: 52,\n",
       " 621: 32,\n",
       " 622: 51,\n",
       " 623: 42,\n",
       " 624: 226,\n",
       " 625: 21,\n",
       " 626: 136,\n",
       " 627: 77,\n",
       " 628: 30,\n",
       " 629: 68,\n",
       " 630: 122,\n",
       " 631: 69,\n",
       " 632: 74,\n",
       " 633: 75,\n",
       " 634: 23,\n",
       " 635: 207,\n",
       " 636: 35,\n",
       " 637: 107,\n",
       " 638: 120,\n",
       " 639: 94,\n",
       " 640: 42,\n",
       " 641: 261,\n",
       " 642: 103,\n",
       " 643: 10,\n",
       " 644: 238,\n",
       " 645: 85,\n",
       " 646: 15,\n",
       " 647: 125,\n",
       " 648: 139,\n",
       " 649: 55,\n",
       " 650: 76,\n",
       " 651: 129,\n",
       " 652: 107,\n",
       " 653: 203,\n",
       " 654: 66,\n",
       " 655: 22,\n",
       " 656: 77,\n",
       " 657: 44,\n",
       " 658: 272,\n",
       " 659: 62,\n",
       " 660: 6,\n",
       " 661: 3,\n",
       " 662: 179,\n",
       " 663: 15,\n",
       " 664: 44,\n",
       " 665: 101,\n",
       " 666: 156,\n",
       " 667: 215,\n",
       " 668: 183,\n",
       " 669: 83,\n",
       " 670: 82,\n",
       " 671: 203,\n",
       " 672: 112,\n",
       " 673: 8,\n",
       " 674: 43,\n",
       " 675: 101,\n",
       " 676: 12,\n",
       " 677: 32,\n",
       " 678: 38,\n",
       " 679: 18,\n",
       " 680: 170,\n",
       " 681: 130,\n",
       " 682: 56,\n",
       " 683: 38,\n",
       " 684: 54,\n",
       " 685: 87,\n",
       " 686: 97,\n",
       " 687: 46,\n",
       " 688: 53,\n",
       " 689: 144,\n",
       " 690: 37,\n",
       " 691: 84,\n",
       " 692: 231,\n",
       " 693: 15,\n",
       " 694: 93,\n",
       " 695: 4,\n",
       " 696: 19,\n",
       " 697: 132,\n",
       " 698: 372,\n",
       " 699: 117,\n",
       " 700: 125,\n",
       " 701: 146,\n",
       " 702: 127,\n",
       " 703: 65,\n",
       " 704: 394,\n",
       " 705: 2,\n",
       " 706: 43,\n",
       " 707: 157,\n",
       " 708: 27,\n",
       " 709: 104,\n",
       " 710: 117,\n",
       " 711: 17,\n",
       " 712: 3,\n",
       " 713: 22,\n",
       " 714: 52,\n",
       " 715: 24,\n",
       " 716: 206,\n",
       " 717: 39,\n",
       " 718: 7,\n",
       " 719: 38,\n",
       " 720: 142,\n",
       " 721: 34,\n",
       " 722: 133,\n",
       " 723: 9,\n",
       " 724: 166,\n",
       " 725: 77,\n",
       " 726: 102,\n",
       " 727: 102,\n",
       " 728: 196,\n",
       " 729: 16,\n",
       " 730: 30,\n",
       " 731: 228,\n",
       " 732: 35,\n",
       " 733: 34,\n",
       " 734: 62,\n",
       " 735: 144,\n",
       " 736: 51,\n",
       " 737: 110,\n",
       " 738: 152,\n",
       " 739: 182,\n",
       " 740: 261,\n",
       " 741: 130,\n",
       " 742: 35,\n",
       " 743: 52,\n",
       " 744: 147,\n",
       " 745: 174,\n",
       " 746: 42,\n",
       " 747: 43,\n",
       " 748: 85,\n",
       " 749: 11,\n",
       " 750: 33,\n",
       " 751: 47,\n",
       " 752: 36,\n",
       " 753: 180,\n",
       " 754: 19,\n",
       " 755: 16,\n",
       " 756: 26,\n",
       " 757: 9,\n",
       " 758: 69,\n",
       " 759: 118,\n",
       " 760: 146,\n",
       " 761: 81,\n",
       " 762: 169,\n",
       " 763: 50,\n",
       " 764: 18,\n",
       " 765: 31,\n",
       " 766: 14,\n",
       " 767: 179,\n",
       " 768: 93,\n",
       " 769: 89,\n",
       " 770: 21,\n",
       " 771: 47,\n",
       " 772: 214,\n",
       " 773: 142,\n",
       " 774: 11,\n",
       " 775: 11,\n",
       " 776: 17,\n",
       " 777: 76,\n",
       " 778: 106,\n",
       " 779: 120,\n",
       " 780: 23,\n",
       " 781: 137,\n",
       " 782: 2,\n",
       " 783: 119,\n",
       " 784: 33,\n",
       " 785: 69,\n",
       " 786: 54,\n",
       " 787: 56,\n",
       " 788: 17,\n",
       " 789: 34,\n",
       " 790: 27,\n",
       " 791: 58,\n",
       " 792: 137,\n",
       " 793: 40,\n",
       " 794: 98,\n",
       " 795: 43,\n",
       " 796: 25,\n",
       " 797: 255,\n",
       " 798: 120,\n",
       " 799: 61,\n",
       " 800: 121,\n",
       " 801: 91,\n",
       " 802: 42,\n",
       " 803: 55,\n",
       " 804: 108,\n",
       " 805: 32,\n",
       " 806: 4,\n",
       " 807: 18,\n",
       " 808: 87,\n",
       " 809: 18,\n",
       " 810: 39,\n",
       " 811: 7,\n",
       " 812: 83,\n",
       " 813: 39,\n",
       " 814: 79,\n",
       " 815: 48,\n",
       " 816: 166,\n",
       " 817: 38,\n",
       " 818: 123,\n",
       " 819: 16,\n",
       " 820: 171,\n",
       " 821: 69,\n",
       " 822: 220,\n",
       " 823: 54,\n",
       " 824: 186,\n",
       " 825: 158,\n",
       " 826: 141,\n",
       " 827: 11,\n",
       " 828: 2,\n",
       " 829: 89,\n",
       " 830: 83,\n",
       " 831: 62,\n",
       " 832: 91,\n",
       " 833: 29,\n",
       " 834: 79,\n",
       " 835: 256,\n",
       " 836: 49,\n",
       " 837: 256,\n",
       " 838: 80,\n",
       " 839: 262,\n",
       " 840: 53,\n",
       " 841: 22,\n",
       " 842: 42,\n",
       " 843: 145,\n",
       " 844: 183,\n",
       " 845: 65,\n",
       " 846: 101,\n",
       " 847: 62,\n",
       " 848: 82,\n",
       " 849: 15,\n",
       " 850: 60,\n",
       " 851: 131,\n",
       " 852: 39,\n",
       " 853: 208,\n",
       " 854: 97,\n",
       " 855: 28,\n",
       " 856: 25,\n",
       " 857: 91,\n",
       " 858: 49,\n",
       " 859: 105,\n",
       " 860: 121,\n",
       " 861: 184,\n",
       " 862: 103,\n",
       " 863: 146,\n",
       " 864: 116,\n",
       " 865: 92,\n",
       " 866: 84,\n",
       " 867: 81,\n",
       " 868: 32,\n",
       " 869: 106,\n",
       " 870: 142,\n",
       " 871: 32,\n",
       " 872: 63,\n",
       " 873: 37,\n",
       " 874: 15,\n",
       " 875: 138,\n",
       " 876: 35,\n",
       " 877: 29,\n",
       " 878: 24,\n",
       " 879: 35,\n",
       " 880: 13,\n",
       " 881: 98,\n",
       " 882: 187,\n",
       " 883: 239,\n",
       " 884: 9,\n",
       " 885: 320,\n",
       " 886: 25,\n",
       " 887: 93,\n",
       " 888: 11,\n",
       " 889: 50,\n",
       " 890: 19,\n",
       " 891: 40,\n",
       " 892: 16,\n",
       " 893: 29,\n",
       " 894: 4,\n",
       " 895: 64,\n",
       " 896: 144,\n",
       " 897: 148,\n",
       " 898: 9,\n",
       " 899: 75,\n",
       " 900: 33,\n",
       " 901: 31,\n",
       " 902: 16,\n",
       " 903: 18,\n",
       " 904: 321,\n",
       " 905: 46,\n",
       " 906: 58,\n",
       " 907: 38,\n",
       " 908: 102,\n",
       " 909: 143,\n",
       " 910: 96,\n",
       " 911: 158,\n",
       " 912: 171,\n",
       " 913: 98,\n",
       " 914: 103,\n",
       " 915: 33,\n",
       " 916: 42,\n",
       " 917: 22,\n",
       " 918: 57,\n",
       " 919: 123,\n",
       " 920: 104,\n",
       " 921: 35,\n",
       " 922: 15,\n",
       " 923: 5,\n",
       " 924: 87,\n",
       " 925: 11,\n",
       " 926: 118,\n",
       " 927: 83,\n",
       " 928: 128,\n",
       " 929: 9,\n",
       " 930: 16,\n",
       " 931: 91,\n",
       " 932: 3,\n",
       " 933: 21,\n",
       " 934: 41,\n",
       " 935: 97,\n",
       " 936: 150,\n",
       " 937: 29,\n",
       " 938: 77,\n",
       " 939: 70,\n",
       " 940: 151,\n",
       " 941: 111,\n",
       " 942: 23,\n",
       " 943: 19,\n",
       " 944: 324,\n",
       " 945: 15,\n",
       " 946: 28,\n",
       " 947: 31,\n",
       " 948: 79,\n",
       " 949: 223,\n",
       " 950: 16,\n",
       " 951: 107,\n",
       " 952: 49,\n",
       " 953: 277,\n",
       " 954: 27,\n",
       " 955: 22,\n",
       " 956: 127,\n",
       " 957: 118,\n",
       " 958: 74,\n",
       " 959: 27,\n",
       " 960: 30,\n",
       " 961: 193,\n",
       " 962: 163,\n",
       " 963: 82,\n",
       " 964: 77,\n",
       " 965: 23,\n",
       " 966: 14,\n",
       " 967: 79,\n",
       " 968: 160,\n",
       " 969: 36,\n",
       " 970: 47,\n",
       " 971: 236,\n",
       " 972: 85,\n",
       " 973: 199,\n",
       " 974: 139,\n",
       " 975: 104,\n",
       " 976: 50,\n",
       " 977: 55,\n",
       " 978: 30,\n",
       " 979: 68,\n",
       " 980: 21,\n",
       " 981: 181,\n",
       " 982: 84,\n",
       " 983: 10,\n",
       " 984: 146,\n",
       " 985: 67,\n",
       " 986: 238,\n",
       " 987: 206,\n",
       " 988: 39,\n",
       " 989: 8,\n",
       " 990: 56,\n",
       " 991: 13,\n",
       " 992: 214,\n",
       " 993: 47,\n",
       " 994: 91,\n",
       " 995: 86,\n",
       " 996: 151,\n",
       " 997: 145,\n",
       " 998: 286,\n",
       " 999: 36,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = XX.sort_values(by=[\"user\"], ascending=True)\n",
    "XX\n",
    "curr_user = -1\n",
    "\n",
    "userItem = {}\n",
    "for index, row in XX.iterrows():\n",
    "    if (row[\"user\"] != curr_user):\n",
    "        curr_user +=1\n",
    "        userItem[curr_user] = 0\n",
    "        \n",
    "    mostPopRating = dictItem[row[\"item\"]] \n",
    "    \n",
    "    if(mostPopRating == row[\"rating\"]):\n",
    "        userItem[curr_user] = userItem[curr_user] + 1\n",
    "userItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "176b3873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_interactions</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>neutral_ratings</th>\n",
       "      <th>likes_ratio</th>\n",
       "      <th>dislikes_ratio</th>\n",
       "      <th>interaction_balance</th>\n",
       "      <th>neutral_ratio</th>\n",
       "      <th>balance_ratio</th>\n",
       "      <th>user</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.324786</td>\n",
       "      <td>117</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>38</td>\n",
       "      <td>0.316239</td>\n",
       "      <td>0.324786</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071856</td>\n",
       "      <td>167</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>0.365269</td>\n",
       "      <td>0.293413</td>\n",
       "      <td>12</td>\n",
       "      <td>0.341317</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.811321</td>\n",
       "      <td>106</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>86</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>100</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>65</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rating  total_interactions  likes  dislikes  neutral_ratings  \\\n",
       "0        0.324786                 117     59        21               37   \n",
       "1        0.629630                  27     17         0               10   \n",
       "2        0.071856                 167     61        49               57   \n",
       "3        0.811321                 106     88         2               16   \n",
       "4        0.650000                 100     66         1               33   \n",
       "\n",
       "   likes_ratio  dislikes_ratio  interaction_balance  neutral_ratio  \\\n",
       "0     0.504274        0.179487                   38       0.316239   \n",
       "1     0.629630        0.000000                   17       0.370370   \n",
       "2     0.365269        0.293413                   12       0.341317   \n",
       "3     0.830189        0.018868                   86       0.150943   \n",
       "4     0.660000        0.010000                   65       0.330000   \n",
       "\n",
       "   balance_ratio  user  label  \n",
       "0       0.324786     0      1  \n",
       "1       0.629630     1      0  \n",
       "2       0.071856     2      1  \n",
       "3       0.811321     3      0  \n",
       "4       0.650000     4      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping by user and creating aggregated features\n",
    "df_grouped = XX.groupby('user').agg(\n",
    "    average_rating=('rating', 'mean'),\n",
    "    total_interactions=('rating', 'size'),\n",
    "    likes=('rating', lambda x: (x == 1).sum()),\n",
    "    dislikes=('rating', lambda x: (x == -1).sum()),\n",
    "    neutral_ratings=('rating', lambda x: (x == 0).sum())\n",
    ")\n",
    "df_grouped['likes_ratio'] = df_grouped['likes'] / df_grouped['total_interactions']\n",
    "df_grouped['dislikes_ratio'] = df_grouped['dislikes'] / df_grouped['total_interactions']\n",
    "df_grouped['interaction_balance'] = df_grouped['likes'] - df_grouped['dislikes']\n",
    "df_grouped['neutral_ratio'] = df_grouped['neutral_ratings'] / df_grouped['total_interactions']\n",
    "df_grouped['balance_ratio'] = df_grouped['interaction_balance'] / df_grouped['total_interactions']\n",
    "\n",
    "# Merging with labels to create a single DataFrame\n",
    "df_final = df_grouped.merge(yy, left_index=True, right_on='user')\n",
    "\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b22b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_interactions</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>meh</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>cv</th>\n",
       "      <th>followed majority</th>\n",
       "      <th>followed majority %</th>\n",
       "      <th>user</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>19.078784</td>\n",
       "      <td>20.662943</td>\n",
       "      <td>64</td>\n",
       "      <td>0.547009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>8.544004</td>\n",
       "      <td>42.019691</td>\n",
       "      <td>19</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>6.110101</td>\n",
       "      <td>4.736512</td>\n",
       "      <td>64</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>46.144700</td>\n",
       "      <td>48.403531</td>\n",
       "      <td>69</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>32.501282</td>\n",
       "      <td>41.668310</td>\n",
       "      <td>66</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_interactions  likes  dislikes  meh        mean        std         cv  \\\n",
       "0                 117     59        21   37   92.333333  19.078784  20.662943   \n",
       "1                  27     17         0   10   20.333333   8.544004  42.019691   \n",
       "2                 167     61        49   57  129.000000   6.110101   4.736512   \n",
       "3                 106     88         2   16   95.333333  46.144700  48.403531   \n",
       "4                 100     66         1   33   78.000000  32.501282  41.668310   \n",
       "\n",
       "   followed majority  followed majority %  user  label  \n",
       "0                 64             0.547009     0      1  \n",
       "1                 19             0.703704     1      0  \n",
       "2                 64             0.383234     2      1  \n",
       "3                 69             0.650943     3      0  \n",
       "4                 66             0.660000     4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = XX.groupby('user').agg(\n",
    "    total_interactions=('rating', 'size'),\n",
    "    likes=('rating', lambda x: (x == 1).sum()),\n",
    "    dislikes=('rating', lambda x: (x == -1).sum()),\n",
    "    meh=('rating', lambda x: (x == 0).sum())\n",
    ")\n",
    "df_grouped['mean'] = df_grouped['likes'] + df_grouped['dislikes'] + df_grouped['meh'] / 3\n",
    "df_grouped['std'] = df_grouped[['likes', 'dislikes', 'meh']].std(axis=1)\n",
    "df_grouped['cv'] = df_grouped['std']/df_grouped['mean'] * 100\n",
    "\n",
    "df_grouped['followed majority'] = pd.DataFrame(userItem.values())\n",
    "df_grouped['followed majority %'] = df_grouped['followed majority'] / df_grouped['total_interactions']\n",
    "# df_grouped.drop(['mean'], axis=1, inplace=True)\n",
    "# df_grouped.drop(['std'], axis=1, inplace=True)\n",
    "\n",
    "# Merging with labels to create a single DataFrame\n",
    "df_final = df_grouped.merge(yy, left_index=True, right_on='user')\n",
    "\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe5da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "# # Splitting the data into training and validation sets\n",
    "# features = df_final.columns.difference(['user', 'label'])\n",
    "# X = df_final[features]\n",
    "# y = df_final['label']\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "# # Scaling the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# # # Training a logistic regression model\n",
    "# # # logreg = LogisticRegression(solver='saga',max_iter=1000, random_state=42, penalty='elasticnet', l1_ratio=0, C=1.0)\n",
    "# # logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# # logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# logreg = LogisticRegression()\n",
    "\n",
    "# param_grid = [    \n",
    "#     {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#     'C' : np.logspace(-4, 4, 20),\n",
    "#     'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "#     'max_iter' : [100, 1000, 2500, 5000, 10000, 25000]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# clf = GridSearchCV(logreg, param_grid = param_grid, scoring='roc_auc', cv = cv, verbose=True, n_jobs=-1)\n",
    "# best_clf = clf.fit(X_train_scaled,y_train)\n",
    "# best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a56911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.76\n",
      "Recall: 0.6333333333333333\n",
      "F1-score: 0.6909090909090909\n",
      "ROC AUC for 2-layer Neural Network: 0.8965833333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "features = df_final.columns.difference(['user', 'label'])\n",
    "X = df_final[features]\n",
    "y = df_final['label']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=11, stratify=y)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Training a 2-layer neural network\n",
    "# Define the hyperparameters\n",
    "hidden_layer_sizes = (50, 10)  # The number of neurons in each hidden layer\n",
    "activation = 'tanh'  # Activation function for the hidden layers ('logistic', 'tanh', 'relu', etc.)\n",
    "solver = 'adam'  # The optimization algorithm ('adam', 'sgd', 'lbfgs', etc.)\n",
    "alpha = 0.0001  # L2 regularization parameter\n",
    "learning_rate = 'adaptive'  # The learning rate schedule for weight updates ('constant', 'invscaling', 'adaptive')\n",
    "max_iter = 2000  # Maximum number of iterations\n",
    "random_state = 44  # Seed for random initialization\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate,\n",
    "    max_iter=max_iter,\n",
    "    random_state=random_state,\n",
    "    batch_size=410,\n",
    "    beta_1=0.7,\n",
    "    beta_2=0.994\n",
    ")\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicting probabilities for the validation set\n",
    "mlp_probs = mlp.predict_proba(X_val_scaled)[:, 1]\n",
    "mlp_auc = roc_auc_score(y_val, mlp_probs)\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
    "mlp_preds = (mlp_probs >= 0.50).astype(int)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_val, mlp_preds)\n",
    "recall = recall_score(y_val, mlp_preds)\n",
    "f1 = f1_score(y_val, mlp_preds)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"ROC AUC for 2-layer Neural Network:\", mlp_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7600c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def get_scores(actual, pred):\n",
    "    precision = precision_score(actual, pred)\n",
    "    recall = recall_score(actual, pred)\n",
    "    f1 = f1_score(actual, pred)\n",
    "    auc_score = roc_auc_score(actual, pred)\n",
    "    \n",
    "    return {\"Precision\":precision, \"Recall\":recall, \"F1_Score\":f1, \"AUC\":auc_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd6dadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation sets\n",
    "features = df_final.columns.difference(['user', 'label'])\n",
    "X = df_final[features]\n",
    "y = df_final['label']\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=11, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_val, y_val, test_size=0.5, random_state=11)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09ce94c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Using CPU.\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 1s 7ms/step - loss: 0.6561 - accuracy: 0.7703 - val_loss: 0.4567 - val_accuracy: 0.7846\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8077 - val_loss: 0.4462 - val_accuracy: 0.7897\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8077 - val_loss: 0.4248 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8209 - val_loss: 0.4235 - val_accuracy: 0.8000\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8209 - val_loss: 0.4229 - val_accuracy: 0.8103\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8242 - val_loss: 0.4065 - val_accuracy: 0.8051\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8264 - val_loss: 0.4168 - val_accuracy: 0.8154\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8330 - val_loss: 0.4234 - val_accuracy: 0.8154\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8385 - val_loss: 0.4114 - val_accuracy: 0.8205\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8363 - val_loss: 0.4010 - val_accuracy: 0.8154\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8330 - val_loss: 0.4041 - val_accuracy: 0.8308\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8429 - val_loss: 0.4111 - val_accuracy: 0.8359\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8418 - val_loss: 0.4107 - val_accuracy: 0.8256\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8440 - val_loss: 0.4062 - val_accuracy: 0.8308\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8407 - val_loss: 0.3976 - val_accuracy: 0.8410\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8451 - val_loss: 0.4020 - val_accuracy: 0.8256\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8451 - val_loss: 0.4053 - val_accuracy: 0.8359\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8462 - val_loss: 0.4014 - val_accuracy: 0.8359\n",
      "Epoch 19/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8418 - val_loss: 0.4088 - val_accuracy: 0.8410\n",
      "Epoch 20/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8473 - val_loss: 0.4156 - val_accuracy: 0.8359\n",
      "Epoch 21/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8495 - val_loss: 0.4138 - val_accuracy: 0.8359\n",
      "Epoch 22/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8516 - val_loss: 0.4146 - val_accuracy: 0.8205\n",
      "Epoch 23/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8418 - val_loss: 0.4024 - val_accuracy: 0.8513\n",
      "Epoch 24/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8549 - val_loss: 0.4130 - val_accuracy: 0.8410\n",
      "Epoch 25/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8473 - val_loss: 0.3971 - val_accuracy: 0.8410\n",
      "Epoch 26/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8495 - val_loss: 0.4180 - val_accuracy: 0.8256\n",
      "Epoch 27/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8484 - val_loss: 0.3948 - val_accuracy: 0.8462\n",
      "Epoch 28/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8505 - val_loss: 0.3989 - val_accuracy: 0.8513\n",
      "Epoch 29/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8505 - val_loss: 0.3962 - val_accuracy: 0.8462\n",
      "Epoch 30/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8484 - val_loss: 0.4095 - val_accuracy: 0.8410\n",
      "Epoch 31/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8505 - val_loss: 0.3995 - val_accuracy: 0.8462\n",
      "Epoch 32/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8549 - val_loss: 0.4066 - val_accuracy: 0.8410\n",
      "Epoch 33/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8505 - val_loss: 0.4037 - val_accuracy: 0.8410\n",
      "Epoch 34/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8516 - val_loss: 0.4023 - val_accuracy: 0.8359\n",
      "Epoch 35/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8582 - val_loss: 0.4014 - val_accuracy: 0.8513\n",
      "Epoch 36/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8560 - val_loss: 0.4166 - val_accuracy: 0.8462\n",
      "Epoch 37/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8527 - val_loss: 0.3989 - val_accuracy: 0.8462\n",
      "Epoch 38/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8582 - val_loss: 0.4151 - val_accuracy: 0.8410\n",
      "Epoch 39/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8516 - val_loss: 0.4076 - val_accuracy: 0.8513\n",
      "Epoch 40/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8538 - val_loss: 0.4023 - val_accuracy: 0.8359\n",
      "Epoch 41/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8582 - val_loss: 0.4063 - val_accuracy: 0.8410\n",
      "Epoch 42/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8549 - val_loss: 0.4125 - val_accuracy: 0.8462\n",
      "Epoch 43/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8538 - val_loss: 0.4135 - val_accuracy: 0.8359\n",
      "Epoch 44/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8637 - val_loss: 0.4020 - val_accuracy: 0.8410\n",
      "Epoch 45/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8571 - val_loss: 0.4091 - val_accuracy: 0.8359\n",
      "Epoch 46/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8582 - val_loss: 0.4055 - val_accuracy: 0.8410\n",
      "Epoch 47/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8626 - val_loss: 0.4156 - val_accuracy: 0.8513\n",
      "Epoch 48/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8560 - val_loss: 0.4150 - val_accuracy: 0.8513\n",
      "Epoch 49/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8571 - val_loss: 0.4061 - val_accuracy: 0.8462\n",
      "Epoch 50/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8604 - val_loss: 0.4120 - val_accuracy: 0.8410\n",
      "Epoch 51/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8582 - val_loss: 0.4054 - val_accuracy: 0.8359\n",
      "Epoch 52/200\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8593 - val_loss: 0.4201 - val_accuracy: 0.8410\n",
      "Epoch 53/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8604 - val_loss: 0.4190 - val_accuracy: 0.8359\n",
      "Epoch 54/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8582 - val_loss: 0.4093 - val_accuracy: 0.8410\n",
      "Epoch 55/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8626 - val_loss: 0.4219 - val_accuracy: 0.8359\n",
      "Epoch 56/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8637 - val_loss: 0.4223 - val_accuracy: 0.8513\n",
      "Epoch 57/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8582 - val_loss: 0.4227 - val_accuracy: 0.8308\n",
      "Epoch 58/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8582 - val_loss: 0.4156 - val_accuracy: 0.8462\n",
      "Epoch 59/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8648 - val_loss: 0.4205 - val_accuracy: 0.8410\n",
      "Epoch 60/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8604 - val_loss: 0.4107 - val_accuracy: 0.8462\n",
      "Epoch 61/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8582 - val_loss: 0.4127 - val_accuracy: 0.8359\n",
      "Epoch 62/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8593 - val_loss: 0.4195 - val_accuracy: 0.8410\n",
      "Epoch 63/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8659 - val_loss: 0.4100 - val_accuracy: 0.8410\n",
      "Epoch 64/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8648 - val_loss: 0.4241 - val_accuracy: 0.8410\n",
      "Epoch 65/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8593 - val_loss: 0.4116 - val_accuracy: 0.8462\n",
      "Epoch 66/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8670 - val_loss: 0.4170 - val_accuracy: 0.8410\n",
      "Epoch 67/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8637 - val_loss: 0.4117 - val_accuracy: 0.8462\n",
      "Epoch 68/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8626 - val_loss: 0.4190 - val_accuracy: 0.8410\n",
      "Epoch 69/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8615 - val_loss: 0.4139 - val_accuracy: 0.8410\n",
      "Epoch 70/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8626 - val_loss: 0.4284 - val_accuracy: 0.8359\n",
      "Epoch 71/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8615 - val_loss: 0.4230 - val_accuracy: 0.8410\n",
      "Epoch 72/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8615 - val_loss: 0.4253 - val_accuracy: 0.8308\n",
      "Epoch 73/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8692 - val_loss: 0.4322 - val_accuracy: 0.8359\n",
      "Epoch 74/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8681 - val_loss: 0.4229 - val_accuracy: 0.8462\n",
      "Epoch 75/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8648 - val_loss: 0.4349 - val_accuracy: 0.8359\n",
      "Epoch 76/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8692 - val_loss: 0.4181 - val_accuracy: 0.8410\n",
      "Epoch 77/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8659 - val_loss: 0.4171 - val_accuracy: 0.8513\n",
      "Epoch 78/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8659 - val_loss: 0.4394 - val_accuracy: 0.8410\n",
      "Epoch 79/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8659 - val_loss: 0.4233 - val_accuracy: 0.8462\n",
      "Epoch 80/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8703 - val_loss: 0.4324 - val_accuracy: 0.8256\n",
      "Epoch 81/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8736 - val_loss: 0.4270 - val_accuracy: 0.8359\n",
      "Epoch 82/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8670 - val_loss: 0.4436 - val_accuracy: 0.8256\n",
      "Epoch 83/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8725 - val_loss: 0.4224 - val_accuracy: 0.8462\n",
      "Epoch 84/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8648 - val_loss: 0.4263 - val_accuracy: 0.8308\n",
      "Epoch 85/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8670 - val_loss: 0.4349 - val_accuracy: 0.8462\n",
      "Epoch 86/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8692 - val_loss: 0.4477 - val_accuracy: 0.8359\n",
      "Epoch 87/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8670 - val_loss: 0.4529 - val_accuracy: 0.8359\n",
      "Epoch 88/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8593 - val_loss: 0.4254 - val_accuracy: 0.8462\n",
      "Epoch 89/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8659 - val_loss: 0.4391 - val_accuracy: 0.8410\n",
      "Epoch 90/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8703 - val_loss: 0.4347 - val_accuracy: 0.8256\n",
      "Epoch 91/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8703 - val_loss: 0.4520 - val_accuracy: 0.8359\n",
      "Epoch 92/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8692 - val_loss: 0.4364 - val_accuracy: 0.8308\n",
      "Epoch 93/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8692 - val_loss: 0.4662 - val_accuracy: 0.8154\n",
      "Epoch 94/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8659 - val_loss: 0.4232 - val_accuracy: 0.8359\n",
      "Epoch 95/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8648 - val_loss: 0.4306 - val_accuracy: 0.8308\n",
      "Epoch 96/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8692 - val_loss: 0.4272 - val_accuracy: 0.8410\n",
      "Epoch 97/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8769 - val_loss: 0.4472 - val_accuracy: 0.8359\n",
      "Epoch 98/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8659 - val_loss: 0.4334 - val_accuracy: 0.8359\n",
      "Epoch 99/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8714 - val_loss: 0.4425 - val_accuracy: 0.8308\n",
      "Epoch 100/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8670 - val_loss: 0.4530 - val_accuracy: 0.8256\n",
      "Epoch 101/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8659 - val_loss: 0.4543 - val_accuracy: 0.8205\n",
      "Epoch 102/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8714 - val_loss: 0.4403 - val_accuracy: 0.8359\n",
      "Epoch 103/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8747 - val_loss: 0.4360 - val_accuracy: 0.8359\n",
      "Epoch 104/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8769 - val_loss: 0.4701 - val_accuracy: 0.8308\n",
      "Epoch 105/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8615 - val_loss: 0.4491 - val_accuracy: 0.8256\n",
      "Epoch 106/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8626 - val_loss: 0.4506 - val_accuracy: 0.8308\n",
      "Epoch 107/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8714 - val_loss: 0.4469 - val_accuracy: 0.8256\n",
      "Epoch 108/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8692 - val_loss: 0.4392 - val_accuracy: 0.8359\n",
      "Epoch 109/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8747 - val_loss: 0.4405 - val_accuracy: 0.8410\n",
      "Epoch 110/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8714 - val_loss: 0.4622 - val_accuracy: 0.8256\n",
      "Epoch 111/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8692 - val_loss: 0.4494 - val_accuracy: 0.8308\n",
      "Epoch 112/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8769 - val_loss: 0.4434 - val_accuracy: 0.8359\n",
      "Epoch 113/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8714 - val_loss: 0.4543 - val_accuracy: 0.8308\n",
      "Epoch 114/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8681 - val_loss: 0.4565 - val_accuracy: 0.8256\n",
      "Epoch 115/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8659 - val_loss: 0.4530 - val_accuracy: 0.8308\n",
      "Epoch 116/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8681 - val_loss: 0.4525 - val_accuracy: 0.8308\n",
      "Epoch 117/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8703 - val_loss: 0.4554 - val_accuracy: 0.8256\n",
      "Epoch 118/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8692 - val_loss: 0.4490 - val_accuracy: 0.8308\n",
      "Epoch 119/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8747 - val_loss: 0.4617 - val_accuracy: 0.8205\n",
      "Epoch 120/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8736 - val_loss: 0.4694 - val_accuracy: 0.8308\n",
      "Epoch 121/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8736 - val_loss: 0.4628 - val_accuracy: 0.8308\n",
      "Epoch 122/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8714 - val_loss: 0.4694 - val_accuracy: 0.8256\n",
      "Epoch 123/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8769 - val_loss: 0.4491 - val_accuracy: 0.8308\n",
      "Epoch 124/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8758 - val_loss: 0.4478 - val_accuracy: 0.8359\n",
      "Epoch 125/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8736 - val_loss: 0.4496 - val_accuracy: 0.8359\n",
      "Epoch 126/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.8791 - val_loss: 0.4552 - val_accuracy: 0.8308\n",
      "Epoch 127/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8725 - val_loss: 0.4701 - val_accuracy: 0.8205\n",
      "Epoch 128/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8835 - val_loss: 0.4925 - val_accuracy: 0.8359\n",
      "Epoch 129/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8736 - val_loss: 0.4541 - val_accuracy: 0.8308\n",
      "Epoch 130/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8780 - val_loss: 0.4576 - val_accuracy: 0.8359\n",
      "Epoch 131/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8769 - val_loss: 0.4577 - val_accuracy: 0.8359\n",
      "Epoch 132/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8791 - val_loss: 0.4648 - val_accuracy: 0.8308\n",
      "Epoch 133/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8780 - val_loss: 0.4706 - val_accuracy: 0.8256\n",
      "Epoch 134/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8791 - val_loss: 0.4804 - val_accuracy: 0.8308\n",
      "Epoch 135/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8802 - val_loss: 0.4933 - val_accuracy: 0.8256\n",
      "Epoch 136/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8802 - val_loss: 0.4694 - val_accuracy: 0.8359\n",
      "Epoch 137/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8824 - val_loss: 0.4735 - val_accuracy: 0.8205\n",
      "Epoch 138/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.8802 - val_loss: 0.5025 - val_accuracy: 0.8154\n",
      "Epoch 139/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8791 - val_loss: 0.4598 - val_accuracy: 0.8359\n",
      "Epoch 140/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8802 - val_loss: 0.4699 - val_accuracy: 0.8359\n",
      "Epoch 141/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8780 - val_loss: 0.4792 - val_accuracy: 0.8154\n",
      "Epoch 142/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8736 - val_loss: 0.4815 - val_accuracy: 0.8205\n",
      "Epoch 143/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8813 - val_loss: 0.4693 - val_accuracy: 0.8256\n",
      "Epoch 144/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8747 - val_loss: 0.4584 - val_accuracy: 0.8308\n",
      "Epoch 145/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8780 - val_loss: 0.4929 - val_accuracy: 0.8154\n",
      "Epoch 146/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8780 - val_loss: 0.4861 - val_accuracy: 0.8256\n",
      "Epoch 147/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.8769 - val_loss: 0.4744 - val_accuracy: 0.8410\n",
      "Epoch 148/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8780 - val_loss: 0.4972 - val_accuracy: 0.8051\n",
      "Epoch 149/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8802 - val_loss: 0.4736 - val_accuracy: 0.8359\n",
      "Epoch 150/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8802 - val_loss: 0.4720 - val_accuracy: 0.8359\n",
      "Epoch 151/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8791 - val_loss: 0.4735 - val_accuracy: 0.8308\n",
      "Epoch 152/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8857 - val_loss: 0.4926 - val_accuracy: 0.8205\n",
      "Epoch 153/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8780 - val_loss: 0.4796 - val_accuracy: 0.8308\n",
      "Epoch 154/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8824 - val_loss: 0.4933 - val_accuracy: 0.8103\n",
      "Epoch 155/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2865 - accuracy: 0.8868 - val_loss: 0.4822 - val_accuracy: 0.8359\n",
      "Epoch 156/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8802 - val_loss: 0.5037 - val_accuracy: 0.8000\n",
      "Epoch 157/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8824 - val_loss: 0.4945 - val_accuracy: 0.8205\n",
      "Epoch 158/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.8824 - val_loss: 0.4842 - val_accuracy: 0.8359\n",
      "Epoch 159/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2914 - accuracy: 0.8868 - val_loss: 0.4810 - val_accuracy: 0.8256\n",
      "Epoch 160/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8747 - val_loss: 0.4852 - val_accuracy: 0.8359\n",
      "Epoch 161/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8813 - val_loss: 0.5091 - val_accuracy: 0.8154\n",
      "Epoch 162/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8824 - val_loss: 0.5216 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8703 - val_loss: 0.4925 - val_accuracy: 0.8308\n",
      "Epoch 164/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8835 - val_loss: 0.4962 - val_accuracy: 0.8256\n",
      "Epoch 165/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.8824 - val_loss: 0.4834 - val_accuracy: 0.8359\n",
      "Epoch 166/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8868 - val_loss: 0.5412 - val_accuracy: 0.7949\n",
      "Epoch 167/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8813 - val_loss: 0.5061 - val_accuracy: 0.8103\n",
      "Epoch 168/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2833 - accuracy: 0.8879 - val_loss: 0.4889 - val_accuracy: 0.8256\n",
      "Epoch 169/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8857 - val_loss: 0.4794 - val_accuracy: 0.8359\n",
      "Epoch 170/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8846 - val_loss: 0.5151 - val_accuracy: 0.8205\n",
      "Epoch 171/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8879 - val_loss: 0.5158 - val_accuracy: 0.8154\n",
      "Epoch 172/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.8868 - val_loss: 0.5174 - val_accuracy: 0.8103\n",
      "Epoch 173/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8846 - val_loss: 0.5596 - val_accuracy: 0.7795\n",
      "Epoch 174/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8824 - val_loss: 0.5082 - val_accuracy: 0.8051\n",
      "Epoch 175/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8890 - val_loss: 0.4755 - val_accuracy: 0.8256\n",
      "Epoch 176/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.8890 - val_loss: 0.5140 - val_accuracy: 0.8205\n",
      "Epoch 177/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8802 - val_loss: 0.4935 - val_accuracy: 0.8154\n",
      "Epoch 178/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8857 - val_loss: 0.5161 - val_accuracy: 0.8103\n",
      "Epoch 179/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.8879 - val_loss: 0.5157 - val_accuracy: 0.8205\n",
      "Epoch 180/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8824 - val_loss: 0.4896 - val_accuracy: 0.8154\n",
      "Epoch 181/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.8901 - val_loss: 0.4932 - val_accuracy: 0.8256\n",
      "Epoch 182/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8956 - val_loss: 0.4987 - val_accuracy: 0.8103\n",
      "Epoch 183/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.8857 - val_loss: 0.5211 - val_accuracy: 0.8103\n",
      "Epoch 184/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2719 - accuracy: 0.8912 - val_loss: 0.5087 - val_accuracy: 0.8308\n",
      "Epoch 185/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8857 - val_loss: 0.4818 - val_accuracy: 0.8359\n",
      "Epoch 186/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.8835 - val_loss: 0.5011 - val_accuracy: 0.8154\n",
      "Epoch 187/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.8956 - val_loss: 0.4840 - val_accuracy: 0.8359\n",
      "Epoch 188/200\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8824 - val_loss: 0.4926 - val_accuracy: 0.8359\n",
      "Epoch 189/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2776 - accuracy: 0.8802 - val_loss: 0.4956 - val_accuracy: 0.8256\n",
      "Epoch 190/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2729 - accuracy: 0.8945 - val_loss: 0.4954 - val_accuracy: 0.8205\n",
      "Epoch 191/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8901 - val_loss: 0.5006 - val_accuracy: 0.8308\n",
      "Epoch 192/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8791 - val_loss: 0.5281 - val_accuracy: 0.8205\n",
      "Epoch 193/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8802 - val_loss: 0.5131 - val_accuracy: 0.8154\n",
      "Epoch 194/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8857 - val_loss: 0.4996 - val_accuracy: 0.8154\n",
      "Epoch 195/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2726 - accuracy: 0.8879 - val_loss: 0.4964 - val_accuracy: 0.8205\n",
      "Epoch 196/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.8901 - val_loss: 0.5376 - val_accuracy: 0.8359\n",
      "Epoch 197/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8835 - val_loss: 0.5006 - val_accuracy: 0.8256\n",
      "Epoch 198/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8945 - val_loss: 0.5072 - val_accuracy: 0.8205\n",
      "Epoch 199/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.8901 - val_loss: 0.5061 - val_accuracy: 0.8154\n",
      "Epoch 200/200\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8923 - val_loss: 0.5309 - val_accuracy: 0.8205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15f1936cfd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Check if GPU is available and set the appropriate device\n",
    "if tf.test.is_gpu_available():\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    print(f'GPU found: {device_name}')\n",
    "else:\n",
    "    print('No GPU found. Using CPU.')\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(9,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the number of output classes (assuming a multi-class classification problem)\n",
    "output_dim = 3  # Adjust based on the number of classes in your classification problem\n",
    "\n",
    "# Convert target labels to one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train, num_classes=output_dim)\n",
    "y_val_encoded = to_categorical(y_val, num_classes=output_dim)\n",
    "\n",
    "# Train the model (provide your own training data and labels)\n",
    "model.fit(X_train_scaled, y_train_encoded, epochs=200, batch_size=16, validation_data=(X_val_scaled, y_val_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c696f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zorko\\anaconda3\\envs\\cs421\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Precision': 0.0, 'Recall': 0.0, 'F1_Score': 0.0, 'AUC': 0.5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)[:, 1]\n",
    "y_pred = (y_pred >= 0.50).astype(int)\n",
    "get_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d51d978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(C=0.03359818286283781)\n",
    "\n",
    "# lr.fit(X_train_scaled,y_train)\n",
    "# # Predicting probabilities for the validation set\n",
    "# logreg_probs = lr.predict_proba(X_val_scaled)[:, 1]\n",
    "# logreg_auc = roc_auc_score(y_val, logreg_probs)\n",
    "\n",
    "# precision = precision_score(y_val, lr.predict(X_val_scaled))\n",
    "# recall = recall_score(y_val, lr.predict(X_val_scaled))\n",
    "# f1 = f1_score(y_val, lr.predict(X_val_scaled))\n",
    "\n",
    "# # Printing the results\n",
    "# print(\"AUC:\", logreg_auc)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ede32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0812544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
